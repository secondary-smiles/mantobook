<!-- Creator     : groff version 1.22.4 -->
<!-- CreationDate: Mon May 29 22:55:33 2023 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>MPI_Allreduce</title>

</head>
<body>
<h1>MPI_Allreduce</h1>



<h2>NAME
<a name="NAME"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>MPI_Allreduce,
MPI_Iallreduce</b> &minus; Combines values from all
processes and distributes the result back to all
processes.</p>

<h2>SYNTAX
<a name="SYNTAX"></a>
</h2>


<h2>C Syntax
<a name="C Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">#include
&lt;mpi.h&gt; <br>
int MPI_Allreduce(const void <i>*sendbuf</i>, void
<i>*recvbuf</i>, int <i>count</i>, <br>
MPI_Datatype <i>datatype</i>, MPI_Op <i>op</i>, MPI_Comm
<i>comm</i>)</p>

<p style="margin-left:11%; margin-top: 1em">int
MPI_Iallreduce(const void <i>*sendbuf</i>, void
<i>*recvbuf</i>, int <i>count</i>, <br>
MPI_Datatype <i>datatype</i>, MPI_Op <i>op</i>, MPI_Comm
<i>comm</i>, <br>
MPI_Request <i>*request</i>)</p>

<h2>Fortran Syntax
<a name="Fortran Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">USE MPI <br>
! or the older form: INCLUDE &rsquo;mpif.h&rsquo; <br>
MPI_ALLREDUCE(<i>SENDBUF</i>, <i>RECVBUF</i>, <i>COUNT</i>,
<i>DATATYPE</i>, <i>OP</i>, <i>COMM</i>, <i>IERROR</i>)</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">


<p>&lt;type&gt;</p></td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">


<p><i>SENDBUF</i>(*), <i>RECVBUF</i>(*)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">


<p>INTEGER</p></td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">


<p><i>COUNT</i>, <i>DATATYPE</i>, <i>OP</i>, <i>COMM</i>,
<i>IERROR</i></p> </td></tr>
</table>


<p style="margin-left:11%; margin-top: 1em">MPI_IALLREDUCE(<i>SENDBUF,
RECVBUF, COUNT, DATATYPE, OP, COMM, REQUEST, IERROR</i>)</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">


<p>&lt;type&gt;</p></td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">


<p><i>SENDBUF</i>(*)<i>, RECVBUF</i>(*)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">


<p>INTEGER</p></td>
<td width="8%"></td>
<td width="8%"></td>
<td width="69%">


<p><i>COUNT, DATATYPE, OP, COMM, REQUEST, IERROR</i></p></td></tr>
</table>

<h2>Fortran 2008 Syntax
<a name="Fortran 2008 Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">USE mpi_f08
<br>
MPI_Allreduce(<i>sendbuf</i>, <i>recvbuf</i>, <i>count</i>,
<i>datatype</i>, <i>op</i>, <i>comm</i>, <i>ierror</i>)</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>TYPE(*), DIMENSION(..), INTENT(IN) :: <i>sendbuf</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>TYPE(*), DIMENSION(..) :: <i>recvbuf</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>INTEGER, INTENT(IN) :: <i>count</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>TYPE(MPI_Datatype), INTENT(IN) :: <i>datatype</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>TYPE(MPI_Op), INTENT(IN) :: <i>op</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>TYPE(MPI_Comm), INTENT(IN) :: <i>comm</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>INTEGER, OPTIONAL, INTENT(OUT) :: <i>ierror</i></p></td></tr>
</table>


<p style="margin-left:11%; margin-top: 1em">MPI_Iallreduce(<i>sendbuf</i>,
<i>recvbuf</i>, <i>count</i>, <i>datatype</i>, <i>op</i>,
<i>comm</i>, <i>request</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%">
</td>
<td width="77%">


<p><i>ierror</i>)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS ::
<i>sendbuf</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(*), DIMENSION(..), ASYNCHRONOUS ::
<i>recvbuf</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER, INTENT(IN) :: <i>count</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Datatype), INTENT(IN) :: <i>datatype</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Op), INTENT(IN) :: <i>op</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Comm), INTENT(IN) :: <i>comm</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Request), INTENT(OUT) :: <i>request</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER, OPTIONAL, INTENT(OUT) :: <i>ierror</i></p></td>
<td width="77%">
</td></tr>
</table>

<h2>C++ Syntax
<a name="C++ Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">#include
&lt;mpi.h&gt; <br>
void MPI::Comm::Allreduce(const void* <i>sendbuf</i>, void*
<i>recvbuf</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>int <i>count</i>, const MPI::Datatype&amp;
<i>datatype</i>, const</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>MPI::Op&amp; <i>op</i>) const=0</p></td></tr>
</table>

<h2>INPUT PARAMETERS
<a name="INPUT PARAMETERS"></a>
</h2>


<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p style="margin-top: 1em">sendbuf</p></td>
<td width="3%"></td>
<td width="69%">


<p style="margin-top: 1em">Starting address of send buffer
(choice).</p> </td>
<td width="5%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>count</p></td>
<td width="3%"></td>
<td width="69%">


<p>Number of elements in send buffer (integer).</p></td>
<td width="5%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>datatype</p></td>
<td width="3%"></td>
<td width="69%">


<p>Datatype of elements of send buffer (handle).</p></td>
<td width="5%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>op</p></td>
<td width="3%"></td>
<td width="69%">


<p>Operation (handle).</p></td>
<td width="5%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>comm</p></td>
<td width="3%"></td>
<td width="69%">


<p>Communicator (handle).</p></td>
<td width="5%">
</td></tr>
</table>

<h2>OUTPUT PARAMETERS
<a name="OUTPUT PARAMETERS"></a>
</h2>


<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="11%">


<p style="margin-top: 1em">recvbuf</p></td>
<td width="4%"></td>
<td width="68%">


<p style="margin-top: 1em">Starting address of receive
buffer (choice).</p></td>
<td width="6%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="11%">


<p>request</p></td>
<td width="4%"></td>
<td width="68%">


<p>Request (handle, non-blocking only).</p></td>
<td width="6%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="11%">


<p>IERROR</p></td>
<td width="4%"></td>
<td width="68%">


<p>Fortran only: Error status (integer).</p></td>
<td width="6%">
</td></tr>
</table>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Same as
MPI_Reduce except that the result appears in the receive
buffer of all the group members.</p>

<p style="margin-left:11%; margin-top: 1em"><b>Example
1:</b> A routine that computes the product of a vector and
an array that are distributed across a group of processes
and returns the answer at all nodes (compare with Example 2,
with MPI_Reduce, below).</p>

<p style="margin-left:11%; margin-top: 1em">SUBROUTINE
PAR_BLAS2(m, n, a, b, c, comm) <br>
REAL a(m), b(m,n) ! local slice of array <br>
REAL c(n) ! result <br>
REAL sum(n) <br>
INTEGER n, comm, i, j, ierr</p>

<p style="margin-left:11%; margin-top: 1em">! local sum
<br>
DO j= 1, n <br>
sum(j) = 0.0 <br>
DO i = 1, m <br>
sum(j) = sum(j) + a(i)*b(i,j) <br>
END DO <br>
END DO</p>

<p style="margin-left:11%; margin-top: 1em">! global sum
<br>
CALL MPI_ALLREDUCE(sum, c, n, MPI_REAL, MPI_SUM, comm,
ierr)</p>

<p style="margin-left:11%; margin-top: 1em">! return result
at all nodes <br>
RETURN</p>

<p style="margin-left:11%; margin-top: 1em"><b>Example
2:</b> A routine that computes the product of a vector and
an array that are distributed across a group of processes
and returns the answer at node zero.</p>

<p style="margin-left:11%; margin-top: 1em">SUBROUTINE
PAR_BLAS2(m, n, a, b, c, comm) <br>
REAL a(m), b(m,n) ! local slice of array <br>
REAL c(n) ! result <br>
REAL sum(n) <br>
INTEGER n, comm, i, j, ierr</p>

<p style="margin-left:11%; margin-top: 1em">! local sum
<br>
DO j= 1, n <br>
sum(j) = 0.0 <br>
DO i = 1, m <br>
sum(j) = sum(j) + a(i)*b(i,j) <br>
END DO <br>
END DO</p>

<p style="margin-left:11%; margin-top: 1em">! global sum
<br>
CALL MPI_REDUCE(sum, c, n, MPI_REAL, MPI_SUM, 0, comm,
ierr)</p>

<p style="margin-left:11%; margin-top: 1em">! return result
at node zero (and garbage at the other nodes) <br>
RETURN</p>

<h2>USE OF IN-PLACE OPTION
<a name="USE OF IN-PLACE OPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">When the
communicator is an intracommunicator, you can perform an
all-reduce operation in-place (the output buffer is used as
the input buffer). Use the variable MPI_IN_PLACE as the
value of <i>sendbuf</i> at all processes.</p>

<p style="margin-left:11%; margin-top: 1em">Note that
MPI_IN_PLACE is a special kind of value; it has the same
restrictions on its use as MPI_BOTTOM.</p>

<p style="margin-left:11%; margin-top: 1em">Because the
in-place option converts the receive buffer into a
send-and-receive buffer, a Fortran binding that includes
INTENT must mark these as INOUT, not OUT.</p>

<h2>WHEN COMMUNICATOR IS AN INTER-COMMUNICATOR
<a name="WHEN COMMUNICATOR IS AN INTER-COMMUNICATOR"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">When the
communicator is an inter-communicator, the reduce operation
occurs in two phases. The data is reduced from all the
members of the first group and received by all the members
of the second group. Then the data is reduced from all the
members of the second group and received by all the members
of the first. The operation exhibits a symmetric,
full-duplex behavior.</p>

<p style="margin-left:11%; margin-top: 1em">When the
communicator is an intra-communicator, these groups are the
same, and the operation occurs in a single phase.</p>

<h2>NOTES ON COLLECTIVE OPERATIONS
<a name="NOTES ON COLLECTIVE OPERATIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The reduction
functions ( <i>MPI_Op</i> ) do not return an error value. As
a result, if the functions detect an error, all they can do
is either call <i>MPI_Abort</i> or silently skip the
problem. Thus, if you change the error handler from
<i>MPI_ERRORS_ARE_FATAL</i> to something else, for example,
<i>MPI_ERRORS_RETURN</i> , then no error may be
indicated.</p>

<h2>ERRORS
<a name="ERRORS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Almost all MPI
routines return an error value; C routines as the value of
the function and Fortran routines in the last argument. C++
functions do not return errors. If the default error handler
is set to MPI::ERRORS_THROW_EXCEPTIONS, then on error the
C++ exception mechanism will be used to throw an
MPI::Exception object.</p>

<p style="margin-left:11%; margin-top: 1em">Before the
error value is returned, the current MPI error handler is
called. By default, this error handler aborts the MPI job,
except for I/O function errors. The error handler may be
changed with MPI_Comm_set_errhandler; the predefined error
handler MPI_ERRORS_RETURN may be used to cause error values
to be returned. Note that MPI does not guarantee that an MPI
program can continue past an error.</p>
<hr>
</body>
</html>
