<!-- Creator     : groff version 1.22.4 -->
<!-- CreationDate: Mon May 29 22:55:35 2023 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>MPI_Accumulate</title>

</head>
<body>
<h1>MPI_Raccumulate</h1>



<h2>NAME
<a name="NAME"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>MPI_Accumulate</b>,
<b>MPI_Raccumulate</b> &minus; Combines the contents of the
origin buffer with that of a target buffer.</p>

<h2>SYNTAX
<a name="SYNTAX"></a>
</h2>


<h2>C Syntax
<a name="C Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">#include
&lt;mpi.h&gt; <br>
int MPI_Accumulate(const void *<i>origin_addr</i>, int
<i>origin_count</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="85%">


<p>MPI_Datatype <i>origin_datatype</i>, int
<i>target_rank</i>,</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="85%">


<p>MPI_Aint <i>target_disp</i>, int
<i>target_count</i>,</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="85%">


<p>MPI_Datatype <i>target_datatype</i>, MPI_Op <i>op</i>,
MPI_Win <i>win</i>)</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">int
MPI_Raccumulate(const void *<i>origin_addr</i>, int
<i>origin_count</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>MPI_Datatype <i>origin_datatype</i>, int
<i>target_rank</i>,</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>MPI_Aint <i>target_disp</i>, int
<i>target_count</i>,</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>MPI_Datatype <i>target_datatype</i>, MPI_Op <i>op</i>,
MPI_Win <i>win</i>,</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>MPI_Request *<i>request</i>)</p></td></tr>
</table>

<h2>Fortran Syntax (see FORTRAN 77 NOTES)
<a name="Fortran Syntax (see FORTRAN 77 NOTES)"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">USE MPI <br>
! or the older form: INCLUDE &rsquo;mpif.h&rsquo; <br>
MPI_ACCUMULATE(<i>ORIGIN_ADDR, ORIGIN_COUNT,
ORIGIN_DATATYPE, TARGET_RANK,</i></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p><i>TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE, OP, WIN,
IERROR</i>)</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>&lt;type&gt; <i>ORIGIN_ADDR</i>(*)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>INTEGER(KIND=MPI_ADDRESS_KIND) <i>TARGET_DISP</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>INTEGER <i>ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK,
TARGET_COUNT,</i></p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p><i>TARGET_DATATYPE, OP, WIN, IERROR</i></p></td></tr>
</table>


<p style="margin-left:11%; margin-top: 1em">MPI_RACCUMULATE(<i>ORIGIN_ADDR,
ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK,</i></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p><i>TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE, OP, WIN,
REQUEST, IERROR</i>)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>&lt;type&gt; <i>ORIGIN_ADDR</i>(*)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>INTEGER(KIND=MPI_ADDRESS_KIND) <i>TARGET_DISP</i></p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>INTEGER <i>ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK,
TARGET_COUNT,</i></p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p><i>TARGET_DATATYPE, OP, WIN, REQUEST, IERROR</i></p></td></tr>
</table>

<h2>Fortran 2008 Syntax
<a name="Fortran 2008 Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">USE mpi_f08
<br>
MPI_Accumulate(<i>origin_addr</i>, <i>origin_count</i>,
<i>origin_datatype</i>, <i>target_rank</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%">
</td>
<td width="77%">


<p><i>target_disp</i>, <i>target_count</i>,
<i>target_datatype</i>, <i>op</i>, <i>win</i>,
<i>ierror</i>)</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS ::
<i>origin_addr</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER, INTENT(IN) :: <i>origin_count</i>,
<i>target_rank</i>, <i>target_count</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Datatype), INTENT(IN) ::
<i>origin_datatype</i>, <i>target_datatype</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) ::
<i>target_disp</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Op), INTENT(IN) :: <i>op</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Win), INTENT(IN) :: <i>win</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER, OPTIONAL, INTENT(OUT) :: <i>ierror</i></p></td>
<td width="77%">
</td></tr>
</table>


<p style="margin-left:11%; margin-top: 1em">MPI_Raccumulate(<i>origin_addr</i>,
<i>origin_count</i>, <i>origin_datatype</i>,
<i>target_rank</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p><i>target_disp</i>, <i>target_count</i>,
<i>target_datatype</i>, <i>op</i>, <i>win</i>,
<i>request,</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%">
</td>
<td width="8%">
</td>
<td width="77%">


<p><i>ierror</i>)</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS ::
<i>origin_addr</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER, INTENT(IN) :: <i>origin_count</i>,
<i>target_rank</i>, <i>target_count</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Datatype), INTENT(IN) ::
<i>origin_datatype</i>, <i>target_datatype</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) ::
<i>target_disp</i></p> </td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Op), INTENT(IN) :: <i>op</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Win), INTENT(IN) :: <i>win</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>TYPE(MPI_Request), INTENT(OUT) :: <i>request</i></p></td>
<td width="77%">
</td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="7%"></td>
<td width="8%">


<p>INTEGER, OPTIONAL, INTENT(OUT) :: <i>ierror</i></p></td>
<td width="77%">
</td></tr>
</table>

<h2>C++ Syntax
<a name="C++ Syntax"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">#include
&lt;mpi.h&gt; <br>
void MPI::Win::Accumulate(const void* <i>origin_addr</i>,
int <i>origin_count</i>,</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>const MPI::Datatype&amp; <i>origin_datatype</i>, int
<i>target_rank</i>,</p> </td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p>MPI::Aint <i>target_disp</i>, int <i>target_count</i>,
const MPI::Datatype&amp;</p></td></tr>
<tr valign="top" align="left">
<td width="8%"></td>
<td width="92%">


<p><i>target_datatype</i>, const MPI::Op&amp; <i>op</i>)
const</p> </td></tr>
</table>

<h2>INPUT PARAMETERS
<a name="INPUT PARAMETERS"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em">origin_addr</p>

<p style="margin-left:26%;">Initial address of buffer
(choice).</p>

<p style="margin-left:11%;">origin_count</p>

<p style="margin-left:26%;">Number of entries in buffer
(nonnegative integer).</p>

<p style="margin-left:11%;">origin_datatype</p>

<p style="margin-left:26%;">Data type of each buffer entry
(handle).</p>

<p style="margin-left:11%;">target_rank</p>

<p style="margin-left:26%;">Rank of target (nonnegative
integer).</p>

<p style="margin-left:11%;">target_disp</p>

<p style="margin-left:26%;">Displacement from start of
window to beginning of target buffer (nonnegative
integer).</p>

<p style="margin-left:11%;">target_count</p>

<p style="margin-left:26%;">Number of entries in target
buffer (nonnegative integer).</p>

<p style="margin-left:11%;">target_datatype</p>

<p style="margin-left:26%;">Data type of each entry in
target buffer (handle).</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>op</p></td>
<td width="11%"></td>
<td width="40%">


<p>Reduce operation (handle).</p></td>
<td width="34%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>win</p></td>
<td width="11%"></td>
<td width="40%">


<p>Window object (handle).</p></td>
<td width="34%">
</td></tr>
</table>

<h2>OUTPUT PARAMETER
<a name="OUTPUT PARAMETER"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em">MPI_Raccumulate:
RMA request</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="9%">


<p>IERROR</p></td>
<td width="6%"></td>
<td width="57%">


<p>Fortran only: Error status (integer).</p></td>
<td width="17%">
</td></tr>
</table>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>



<p style="margin-left:11%; margin-top: 1em"><b>MPI_Accumulate</b>
is a function used for one-sided MPI communication that adds
the contents of the origin buffer (as defined by
<i>origin_addr</i>, <i>origin_count</i>, and
<i>origin_datatype</i>) to the buffer specified by the
arguments <i>target_count</i> and <i>target_datatype</i>, at
offset <i>target_disp</i>, in the target window specified by
<i>target_rank</i> and <i>win</i>, using the operation
<i>op</i>. The target window can only be accessed by
processes within the same node. This is similar to MPI_Put,
except that data is combined into the target area instead of
overwriting it.</p>

<p style="margin-left:11%; margin-top: 1em">Any of the
predefined operations for MPI_Reduce can be used.
User-defined functions cannot be used. For example, if
<i>op</i> is MPI_SUM, each element of the origin buffer is
added to the corresponding element in the target, replacing
the former value in the target.</p>

<p style="margin-left:11%; margin-top: 1em">Each datatype
argument must be a predefined data type or a derived data
type, where all basic components are of the same predefined
data type. Both datatype arguments must be constructed from
the same predefined data type. The operation <i>op</i>
applies to elements of that predefined type. The
<i>target_datatype</i> argument must not specify overlapping
entries, and the target buffer must fit in the target
window.</p>

<p style="margin-left:11%; margin-top: 1em">A new
predefined operation, MPI_REPLACE, is defined. It
corresponds to the associative function f(a, b) =b; that is,
the current value in the target memory is replaced by the
value supplied by the origin.</p>


<p style="margin-left:11%; margin-top: 1em"><b>MPI_Raccumulate</b>
is similar to <b>MPI_Accumulate</b>, except that it
allocates a communication request object and associates it
with the request handle (the argument <i>request</i>) that
can be used to wait or test for completion. The completion
of an <b>MPI_Raccumulate</b> operation indicates that the
<i>origin_addr</i> buffer is free to be updated. It does not
indicate that the operation has completed at the target
window.</p>

<h2>FORTRAN 77 NOTES
<a name="FORTRAN 77 NOTES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The MPI
standard prescribes portable Fortran syntax for the
<i>TARGET_DISP</i> argument only for Fortran 90. FORTRAN 77
users may use the non-portable syntax</p>


<p style="margin-left:11%; margin-top: 1em">INTEGER*MPI_ADDRESS_KIND
<i>TARGET_DISP</i></p>

<p style="margin-left:11%; margin-top: 1em">where
MPI_ADDRESS_KIND is a constant defined in mpif.h and gives
the length of the declared integer in bytes.</p>

<h2>NOTES
<a name="NOTES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">MPI_Put is a
special case of <b>MPI_Accumulate</b>, with the operation
MPI_REPLACE. Note, however, that MPI_Put and
<b>MPI_Accumulate</b> have different constraints on
concurrent updates.</p>

<p style="margin-left:11%; margin-top: 1em">It is the
user&rsquo;s responsibility to guarantee that, when using
the accumulate functions, the target displacement argument
is such that accesses to the window are properly aligned
according to the data type arguments in the call to the
<b>MPI_Accumulate</b> function.</p>

<h2>ERRORS
<a name="ERRORS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Almost all MPI
routines return an error value; C routines as the value of
the function and Fortran routines in the last argument. C++
functions do not return errors. If the default error handler
is set to MPI::ERRORS_THROW_EXCEPTIONS, then on error the
C++ exception mechanism will be used to throw an
MPI::Exception object.</p>

<p style="margin-left:11%; margin-top: 1em">Before the
error value is returned, the current MPI error handler is
called. By default, this error handler aborts the MPI job,
except for I/O function errors. The error handler may be
changed with MPI_Comm_set_errhandler; the predefined error
handler MPI_ERRORS_RETURN may be used to cause error values
to be returned. Note that MPI does not guarantee that an MPI
program can continue past an error.</p>

<h2>SEE ALSO
<a name="SEE ALSO"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">MPI_Put
MPI_Get_accumulate MPI_Reduce</p>
<hr>
</body>
</html>
