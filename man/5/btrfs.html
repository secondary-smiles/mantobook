<!-- Creator     : groff version 1.22.4 -->
<!-- CreationDate: Mon May 29 22:56:53 2023 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>BTRFS</title>

</head>
<body>
<h1>btrfs</h1>



<h2>NAME
<a name="NAME"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">btrfs &minus;
topics about the BTRFS filesystem (mount options, supported
file attributes and other)</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">This document
describes topics related to BTRFS that are not specific to
the tools. Currently covers:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>1.</p></td>
<td width="2%"></td>
<td width="71%">


<p>mount options</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>2.</p></td>
<td width="2%"></td>
<td width="71%">


<p>filesystem features</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>3.</p></td>
<td width="2%"></td>
<td width="71%">


<p>checksum algorithms</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>4.</p></td>
<td width="2%"></td>
<td width="71%">


<p>compression</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>5.</p></td>
<td width="2%"></td>
<td width="71%">


<p>sysfs interface</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>6.</p></td>
<td width="2%"></td>
<td width="71%">


<p>filesystem exclusive operations</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>7.</p></td>
<td width="2%"></td>
<td width="71%">


<p>filesystem limits</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>8.</p></td>
<td width="2%"></td>
<td width="71%">


<p>bootloader support</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>9.</p></td>
<td width="2%"></td>
<td width="71%">


<p>file attributes</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>10.</p></td>
<td width="2%"></td>
<td width="71%">


<p>zoned mode</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>11.</p></td>
<td width="2%"></td>
<td width="71%">


<p>control device</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>12.</p></td>
<td width="2%"></td>
<td width="71%">


<p>filesystems with multiple block group profiles</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>13.</p></td>
<td width="2%"></td>
<td width="71%">


<p>seeding device</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>14.</p></td>
<td width="2%"></td>
<td width="71%">


<p>RAID56 status and recommended practices</p></td>
<td width="12%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>15.</p></td>
<td width="2%"></td>
<td width="71%">


<p>storage model, hardware considerations</p></td>
<td width="12%">
</td></tr>
</table>

<h2>MOUNT OPTIONS
<a name="MOUNT OPTIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>BTRFS
SPECIFIC MOUNT OPTIONS</b> <br>
This section describes mount options specific to BTRFS. For
the generic mount options please refer to <b>mount(8)</b>
manual page. The options are sorted alphabetically
(discarding the <i>no</i> prefix).</p>


<p style="margin-left:11%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:15%;">Most mount options apply to the
whole filesystem and only options in the first mounted
subvolume will take effect. This is due to lack of
implementation and may change in the future. This means that
(for example) you can't set per&minus;subvolume
<i>nodatacow</i>, <i>nodatasum</i>, or <i>compress</i> using
mount options. This should eventually be fixed, but it has
proved to be difficult to implement correctly within the
Linux VFS framework.</p>

<p style="margin-left:11%; margin-top: 1em">Mount options
are processed in order, only the last occurrence of an
option takes effect and may disable other options due to
constraints (see e.g. <i>nodatacow</i> and <i>compress</i>).
The output of <b>mount</b> command shows which options have
been applied. <b><br>
acl, noacl</b></p>

<p style="margin-left:22%;">(default: on)</p>

<p style="margin-left:22%; margin-top: 1em">Enable/disable
support for POSIX Access Control Lists (ACLs). See the
<b>acl(5)</b> manual page for more information about
ACLs.</p>

<p style="margin-left:22%; margin-top: 1em">The support for
ACL is build&minus;time configurable (BTRFS_FS_POSIX_ACL)
and mount fails if <i>acl</i> is requested but the feature
is not compiled in.</p>

<p style="margin-left:11%;"><b>autodefrag,
noautodefrag</b></p>

<p style="margin-left:22%;">(since: 3.0, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Enable
automatic file defragmentation. When enabled, small random
writes into files (in a range of tens of kilobytes,
currently it's 64KiB) are detected and queued up for the
defragmentation process. Not well suited for large database
workloads.</p>

<p style="margin-left:22%; margin-top: 1em">The read
latency may increase due to reading the adjacent blocks that
make up the range for defragmentation, successive write will
merge the blocks in the new location.</p>


<p style="margin-left:22%; margin-top: 1em"><b>WARNING:</b></p>

<p style="margin-left:26%;">Defragmenting with Linux kernel
versions &lt; 3.9 or &acirc;&yen; 3.14&minus;rc2 as well as
with Linux stable kernel versions &acirc;&yen; 3.10.31,
&acirc;&yen; 3.12.12 or &acirc;&yen; 3.13.4 will break up
the reflinks of COW data (for example files copied with
<b>cp &minus;&minus;reflink</b>, snapshots or
de&minus;duplicated data). This may cause considerable
increase of space usage depending on the broken up
reflinks.</p>

<p style="margin-left:11%;"><b>barrier, nobarrier</b></p>

<p style="margin-left:22%;">(default: on)</p>

<p style="margin-left:22%; margin-top: 1em">Ensure that all
IO write operations make it through the device cache and are
stored permanently when the filesystem is at its consistency
checkpoint. This typically means that a flush command is
sent to the device that will synchronize all pending data
and ordinary metadata blocks, then writes the superblock and
issues another flush.</p>

<p style="margin-left:22%; margin-top: 1em">The write
flushes incur a slight hit and also prevent the IO block
scheduler to reorder requests in a more effective way.
Disabling barriers gets rid of that penalty but will most
certainly lead to a corrupted filesystem in case of a crash
or power loss. The ordinary metadata blocks could be yet
unwritten at the time the new superblock is stored
permanently, expecting that the block pointers to metadata
were stored permanently before.</p>

<p style="margin-left:22%; margin-top: 1em">On a device
with a volatile battery&minus;backed write&minus;back cache,
the <i>nobarrier</i> option will not lead to filesystem
corruption as the pending blocks are supposed to make it to
the permanent storage.</p>

<p style="margin-left:11%;"><b>check_int, check_int_data,
check_int_print_mask=&lt;value&gt;</b></p>

<p style="margin-left:22%;">(since: 3.0, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">These debugging
options control the behavior of the integrity checking
module (the BTRFS_FS_CHECK_INTEGRITY config option
required). The main goal is to verify that all blocks from a
given transaction period are properly linked.</p>


<p style="margin-left:22%; margin-top: 1em"><i>check_int</i>
enables the integrity checker module, which examines all
block write requests to ensure on&minus;disk consistency, at
a large memory and CPU cost.</p>


<p style="margin-left:22%; margin-top: 1em"><i>check_int_data</i>
includes extent data in the integrity checks, and implies
the <i>check_int</i> option.</p>


<p style="margin-left:22%; margin-top: 1em"><i>check_int_print_mask</i>
takes a bitmask of BTRFSIC_PRINT_MASK_* values as defined in
<i>fs/btrfs/check&minus;integrity.c</i>, to control the
integrity checker module behavior.</p>

<p style="margin-left:22%; margin-top: 1em">See comments at
the top of <i>fs/btrfs/check&minus;integrity.c</i> for more
information.</p>

<p style="margin-left:11%;"><b>clear_cache</b></p>

<p style="margin-left:22%;">Force clearing and rebuilding
of the free space cache if something has gone wrong.</p>

<p style="margin-left:22%; margin-top: 1em">For free space
cache <i>v1</i>, this only clears (and, unless
<i>nospace_cache</i> is used, rebuilds) the free space cache
for block groups that are modified while the filesystem is
mounted with that option. To actually clear an entire free
space cache <i>v1</i>, see <b>btrfs check
&minus;&minus;clear&minus;space&minus;cache v1</b>.</p>

<p style="margin-left:22%; margin-top: 1em">For free space
cache <i>v2</i>, this clears the entire free space cache. To
do so without requiring to mounting the filesystem, see
<b>btrfs check &minus;&minus;clear&minus;space&minus;cache
v2</b>.</p>

<p style="margin-left:22%; margin-top: 1em">See also:
<i>space_cache</i>.</p>


<p style="margin-left:11%;"><b>commit=&lt;seconds&gt;</b></p>

<p style="margin-left:22%;">(since: 3.12, default: 30)</p>

<p style="margin-left:22%; margin-top: 1em">Set the
interval of periodic transaction commit when data are
synchronized to permanent storage. Higher interval values
lead to larger amount of unwritten data, which has obvious
consequences when the system crashes. The upper bound is not
forced, but a warning is printed if it's more than 300
seconds (5 minutes). Use with care.</p>

<p style="margin-left:11%;"><b>compress,
compress=&lt;type[:level]&gt;, compress&minus;force, <br>
compress&minus;force=&lt;type[:level]&gt;</b></p>

<p style="margin-left:22%;">(default: off, level support
since: 5.1)</p>

<p style="margin-left:22%; margin-top: 1em">Control BTRFS
file data compression. Type may be specified as <i>zlib</i>,
<i>lzo</i>, <i>zstd</i> or <i>no</i> (for no compression,
used for remounting). If no type is specified, <i>zlib</i>
is used. If <i>compress&minus;force</i> is specified, then
compression will always be attempted, but the data may end
up uncompressed if the compression would make them
larger.</p>

<p style="margin-left:22%; margin-top: 1em">Both
<i>zlib</i> and <i>zstd</i> (since version 5.1) expose the
compression level as a tunable knob with higher levels
trading speed and memory (<i>zstd</i>) for higher
compression ratios. This can be set by appending a colon and
the desired level. ZLIB accepts the range [1, 9] and ZSTD
accepts [1, 15]. If no level is set, both currently use a
default level of 3. The value 0 is an alias for the default
level.</p>

<p style="margin-left:22%; margin-top: 1em">Otherwise some
simple heuristics are applied to detect an incompressible
file. If the first blocks written to a file are not
compressible, the whole file is permanently marked to skip
compression. As this is too simple, the
<i>compress&minus;force</i> is a workaround that will
compress most of the files at the cost of some wasted CPU
cycles on failed attempts. Since kernel 4.15, a set of
heuristic algorithms have been improved by using frequency
sampling, repeated pattern detection and Shannon entropy
calculation to avoid that.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">If compression is enabled,
<i>nodatacow</i> and <i>nodatasum</i> are disabled.</p>

<p style="margin-left:11%;"><b>datacow, nodatacow</b></p>

<p style="margin-left:22%;">(default: on)</p>

<p style="margin-left:22%; margin-top: 1em">Enable data
copy&minus;on&minus;write for newly created files.
<i>Nodatacow</i> implies <i>nodatasum</i>, and disables
<i>compression</i>. All files created under <i>nodatacow</i>
are also set the NOCOW file attribute (see
<b>chattr(1)</b>).</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">If <i>nodatacow</i> or
<i>nodatasum</i> are enabled, compression is disabled.</p>

<p style="margin-left:22%; margin-top: 1em">Updates
in&minus;place improve performance for workloads that do
frequent overwrites, at the cost of potential partial
writes, in case the write is interrupted (system crash,
device failure).</p>

<p style="margin-left:11%;"><b>datasum, nodatasum</b></p>

<p style="margin-left:22%;">(default: on)</p>

<p style="margin-left:22%; margin-top: 1em">Enable data
checksumming for newly created files. <i>Datasum</i> implies
<i>datacow</i>, i.e. the normal mode of operation. All files
created under <i>nodatasum</i> inherit the &quot;no
checksums&quot; property, however there's no corresponding
file attribute (see <b>chattr(1)</b>).</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">If <i>nodatacow</i> or
<i>nodatasum</i> are enabled, compression is disabled.</p>

<p style="margin-left:22%; margin-top: 1em">There is a
slight performance gain when checksums are turned off, the
corresponding metadata blocks holding the checksums do not
need to updated. The cost of checksumming of the blocks in
memory is much lower than the IO, modern CPUs feature
hardware support of the checksumming algorithm.</p>

<p style="margin-left:11%;"><b>degraded</b></p>

<p style="margin-left:22%;">(default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Allow mounts
with less devices than the RAID profile constraints require.
A read&minus;write mount (or remount) may fail when there
are too many devices missing, for example if a stripe member
is completely missing from RAID0.</p>

<p style="margin-left:22%; margin-top: 1em">Since 4.14, the
constraint checks have been improved and are verified on the
chunk level, not at the device level. This allows degraded
mounts of filesystems with mixed RAID profiles for data and
metadata, even if the device number constraints would not be
satisfied for some of the profiles.</p>

<p style="margin-left:22%; margin-top: 1em">Example:
metadata &minus;&minus; raid1, data &minus;&minus; single,
devices &minus;&minus; /dev/sda, /dev/sdb</p>

<p style="margin-left:22%; margin-top: 1em">Suppose the
data are completely stored on <i>sda</i>, then missing
<i>sdb</i> will not prevent the mount, even if 1 missing
device would normally prevent (any) <i>single</i> profile to
mount. In case some of the data chunks are stored on
<i>sdb</i>, then the constraint of single/data is not
satisfied and the filesystem cannot be mounted.</p>


<p style="margin-left:11%;"><b>device=&lt;devicepath&gt;</b></p>

<p style="margin-left:22%;">Specify a path to a device that
will be scanned for BTRFS filesystem during mount. This is
usually done automatically by a device manager (like udev)
or using the <b>btrfs device scan</b> command (e.g. run from
the initial ramdisk). In cases where this is not possible
the <i>device</i> mount option can help.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">Booting e.g. a RAID1 system may
fail even if all filesystem's <i>device</i> paths are
provided as the actual device nodes may not be discovered by
the system at that point.</p>

<p style="margin-left:11%;"><b>discard, discard=sync,
discard=async, nodiscard</b></p>

<p style="margin-left:22%;">(default: async when devices
support it since 6.2, async support since: 5.6)</p>

<p style="margin-left:22%; margin-top: 1em">Enable
discarding of freed file blocks. This is useful for SSD
devices, thinly provisioned LUNs, or virtual machine images;
however, every storage layer must support discard for it to
work.</p>

<p style="margin-left:22%; margin-top: 1em">In the
synchronous mode (<i>sync</i> or without option value), lack
of asynchronous queued TRIM on the backing device TRIM can
severely degrade performance, because a synchronous TRIM
operation will be attempted instead. Queued TRIM requires
newer than SATA revision 3.1 chipsets and devices.</p>

<p style="margin-left:22%; margin-top: 1em">The
asynchronous mode (<i>async</i>) gathers extents in larger
chunks before sending them to the devices for TRIM. The
overhead and performance impact should be negligible
compared to the previous mode and it's supposed to be the
preferred mode if needed.</p>

<p style="margin-left:22%; margin-top: 1em">If it is not
necessary to immediately discard freed blocks, then the
<b>fstrim</b> tool can be used to discard all free blocks in
a batch. Scheduling a TRIM during a period of low system
activity will prevent latent interference with the
performance of other operations. Also, a device may ignore
the TRIM command if the range is too small, so running a
batch discard has a greater probability of actually
discarding the blocks.</p>

<p style="margin-left:11%;"><b>enospc_debug,
noenospc_debug</b></p>

<p style="margin-left:22%;">(default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Enable verbose
output for some ENOSPC conditions. It's safe to use but can
be noisy if the system reaches near&minus;full state.</p>


<p style="margin-left:11%;"><b>fatal_errors=&lt;action&gt;</b></p>

<p style="margin-left:22%;">(since: 3.4, default: bug)</p>

<p style="margin-left:22%; margin-top: 1em">Action to take
when encountering a fatal error.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="22%"></td>
<td width="7%">


<p><b>bug</b></p></td>
<td width="3%"></td>
<td width="68%">


<p><i>BUG()</i> on a fatal error, the system will stay in
the crashed state and may be still partially usable, but
reboot is required for full operation</p></td></tr>
<tr valign="top" align="left">
<td width="22%"></td>
<td width="7%">


<p><b>panic</b></p></td>
<td width="3%"></td>
<td width="68%">


<p><i>panic()</i> on a fatal error, depending on other
system configuration, this may be followed by a reboot.
Please refer to the documentation of kernel boot parameters,
e.g. <i>panic</i>, <i>oops</i> or <i>crashkernel</i>.</p></td></tr>
</table>

<p style="margin-left:11%;"><b>flushoncommit,
noflushoncommit</b></p>

<p style="margin-left:22%;">(default: off)</p>

<p style="margin-left:22%; margin-top: 1em">This option
forces any data dirtied by a write in a prior transaction to
commit as part of the current commit, effectively a full
filesystem sync.</p>

<p style="margin-left:22%; margin-top: 1em">This makes the
committed state a fully consistent view of the file system
from the application's perspective (i.e. it includes all
completed file system operations). This was previously the
behavior only when a snapshot was created.</p>

<p style="margin-left:22%; margin-top: 1em">When off, the
filesystem is consistent but buffered writes may last more
than one transaction commit.</p>


<p style="margin-left:11%;"><b>fragment=&lt;type&gt;</b></p>

<p style="margin-left:22%;">(depends on compile&minus;time
option BTRFS_DEBUG, since: 4.4, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">A debugging
helper to intentionally fragment given <i>type</i> of block
groups. The type can be <i>data</i>, <i>metadata</i> or
<i>all</i>. This mount option should not be used outside of
debugging environments and is not recognized if the kernel
config option <i>BTRFS_DEBUG</i> is not enabled.</p>

<p style="margin-left:11%;"><b>nologreplay</b></p>

<p style="margin-left:22%;">(default: off, even
read&minus;only)</p>

<p style="margin-left:22%; margin-top: 1em">The
tree&minus;log contains pending updates to the filesystem
until the full commit. The log is replayed on next mount,
this can be disabled by this option. See also
<i>treelog</i>. Note that <i>nologreplay</i> is the same as
<i>norecovery</i>.</p>


<p style="margin-left:22%; margin-top: 1em"><b>WARNING:</b></p>

<p style="margin-left:26%;">Currently, the tree log is
replayed even with a read&minus;only mount! To disable that
behaviour, mount also with <i>nologreplay</i>.</p>


<p style="margin-left:11%;"><b>max_inline=&lt;bytes&gt;</b></p>

<p style="margin-left:22%;">(default: min(2048, page size)
)</p>

<p style="margin-left:22%; margin-top: 1em">Specify the
maximum amount of space, that can be inlined in a metadata
b&minus;tree leaf. The value is specified in bytes,
optionally with a K suffix (case insensitive). In practice,
this value is limited by the filesystem block size (named
<i>sectorsize</i> at mkfs time), and memory page size of the
system. In case of sectorsize limit, there's some space
unavailable due to leaf headers. For example, a 4KiB
sectorsize, maximum size of inline data is about 3900
bytes.</p>

<p style="margin-left:22%; margin-top: 1em">Inlining can be
completely turned off by specifying 0. This will increase
data block slack if file sizes are much smaller than block
size but will reduce metadata consumption in return.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">The default value has changed
to 2048 in kernel 4.6.</p>


<p style="margin-left:11%;"><b>metadata_ratio=&lt;value&gt;</b></p>

<p style="margin-left:22%;">(default: 0, internal
logic)</p>

<p style="margin-left:22%; margin-top: 1em">Specifies that
1 metadata chunk should be allocated after every
<i>value</i> data chunks. Default behaviour depends on
internal logic, some percent of unused metadata space is
attempted to be maintained but is not always possible if
there's not enough space left for chunk allocation. The
option could be useful to override the internal logic in
favor of the metadata allocation if the expected workload is
supposed to be metadata intense (snapshots, reflinks,
xattrs, inlined files).</p>

<p style="margin-left:11%;"><b>norecovery</b></p>

<p style="margin-left:22%;">(since: 4.5, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Do not attempt
any data recovery at mount time. This will disable
<i>logreplay</i> and avoids other write operations. Note
that this option is the same as <i>nologreplay</i>.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">The opposite option
<i>recovery</i> used to have different meaning but was
changed for consistency with other filesystems, where
<i>norecovery</i> is used for skipping log replay. BTRFS
does the same and in general will try to avoid any write
operations.</p>

<p style="margin-left:11%;"><b>rescan_uuid_tree</b></p>

<p style="margin-left:22%;">(since: 3.12, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Force check and
rebuild procedure of the UUID tree. This should not normally
be needed.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="9%">


<p><b>rescue</b></p></td>
<td width="2%"></td>
<td width="18%">


<p>(since: 5.9)</p></td>
<td width="60%">
</td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">Modes allowing
mount with damaged filesystem structures.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="22%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p style="margin-top: 1em"><i>usebackuproot</i> (since:
5.9, replaces standalone option <i>usebackuproot</i>)</p></td></tr>
<tr valign="top" align="left">
<td width="22%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p><i>nologreplay</i> (since: 5.9, replaces standalone
option <i>nologreplay</i>)</p></td></tr>
<tr valign="top" align="left">
<td width="22%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p><i>ignorebadroots</i>, <i>ibadroots</i> (since:
5.11)</p> </td></tr>
<tr valign="top" align="left">
<td width="22%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p><i>ignoredatacsums</i>, <i>idatacsums</i> (since:
5.11)</p> </td></tr>
<tr valign="top" align="left">
<td width="22%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p><i>all</i> (since: 5.9)</p></td></tr>
</table>

<p style="margin-left:11%;"><b>skip_balance</b></p>

<p style="margin-left:22%;">(since: 3.3, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Skip automatic
resume of an interrupted balance operation. The operation
can later be resumed with <b>btrfs balance resume</b>, or
the paused state can be removed with <b>btrfs balance
cancel</b>. The default behaviour is to resume an
interrupted balance immediately after a volume is
mounted.</p>

<p style="margin-left:11%;"><b>space_cache,
space_cache=&lt;version&gt;, nospace_cache</b></p>

<p style="margin-left:22%;">(<i>nospace_cache</i> since:
3.2, <i>space_cache=v1</i> and <i>space_cache=v2</i> since
4.5, default: <i>space_cache=v2</i>)</p>

<p style="margin-left:22%; margin-top: 1em">Options to
control the free space cache. The free space cache greatly
improves performance when reading block group free space
into memory. However, managing the space cache consumes some
resources, including a small amount of disk space.</p>

<p style="margin-left:22%; margin-top: 1em">There are two
implementations of the free space cache. The original one,
referred to as <i>v1</i>, used to be a safe default but has
been superseded by <i>v2</i>. The <i>v1</i> space cache can
be disabled at mount time with <i>nospace_cache</i> without
clearing.</p>

<p style="margin-left:22%; margin-top: 1em">On very large
filesystems (many terabytes) and certain workloads, the
performance of the <i>v1</i> space cache may degrade
drastically. The <i>v2</i> implementation, which adds a new
b&minus;tree called the free space tree, addresses this
issue. Once enabled, the <i>v2</i> space cache will always
be used and cannot be disabled unless it is cleared. Use
<i>clear_cache,space_cache=v1</i> or
<i>clear_cache,nospace_cache</i> to do so. If <i>v2</i> is
enabled, and <i>v1</i> space cache will be cleared (at the
first mount) and kernels without <i>v2</i> support will only
be able to mount the filesystem in read&minus;only mode. On
an unmounted filesystem the caches (both versions) can be
cleared by &quot;btrfs check
&minus;&minus;clear&minus;space&minus;cache&quot;.</p>

<p style="margin-left:22%; margin-top: 1em">The
<i>btrfs&minus;check(8)</i> and
<i>:doc:`mkfs.btrfs(8)&lt;mkfs.btrfs&gt;</i> commands have
full <i>v2</i> free space cache support since v4.19.</p>

<p style="margin-left:22%; margin-top: 1em">If a version is
not explicitly specified, the default implementation will be
chosen, which is <i>v2</i>.</p>

<p style="margin-left:11%;"><b>ssd, ssd_spread, nossd,
nossd_spread</b></p>

<p style="margin-left:22%;">(default: SSD autodetected)</p>

<p style="margin-left:22%; margin-top: 1em">Options to
control SSD allocation schemes. By default, BTRFS will
enable or disable SSD optimizations depending on status of a
device with respect to rotational or non&minus;rotational
type. This is determined by the contents of
<i>/sys/block/DEV/queue/rotational</i>). If it is 0, the
<i>ssd</i> option is turned on. The option <i>nossd</i> will
disable the autodetection.</p>

<p style="margin-left:22%; margin-top: 1em">The
optimizations make use of the absence of the seek penalty
that's inherent for the rotational devices. The blocks can
be typically written faster and are not offloaded to
separate threads.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">Since 4.14, the block layout
optimizations have been dropped. This used to help with
first generations of SSD devices. Their FTL (flash
translation layer) was not effective and the optimization
was supposed to improve the wear by better aligning blocks.
This is no longer true with modern SSD devices and the
optimization had no real benefit. Furthermore it caused
increased fragmentation. The layout tuning has been kept
intact for the option <i>ssd_spread</i>.</p>

<p style="margin-left:22%; margin-top: 1em">The
<i>ssd_spread</i> mount option attempts to allocate into
bigger and aligned chunks of unused space, and may perform
better on low&minus;end SSDs. <i>ssd_spread</i> implies
<i>ssd</i>, enabling all other SSD heuristics as well. The
option <i>nossd</i> will disable all SSD options while
<i>nossd_spread</i> only disables <i>ssd_spread</i>.</p>

<p style="margin-left:11%;"><b>subvol=&lt;path&gt;</b></p>

<p style="margin-left:22%;">Mount subvolume from
<i>path</i> rather than the toplevel subvolume. The
<i>path</i> is always treated as relative to the toplevel
subvolume. This mount option overrides the default subvolume
set for the given filesystem.</p>


<p style="margin-left:11%;"><b>subvolid=&lt;subvolid&gt;</b></p>

<p style="margin-left:22%;">Mount subvolume specified by a
<i>subvolid</i> number rather than the toplevel subvolume.
You can use <b>btrfs subvolume list</b> of <b>btrfs
subvolume show</b> to see subvolume ID numbers. This mount
option overrides the default subvolume set for the given
filesystem.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">If both <i>subvolid</i> and
<i>subvol</i> are specified, they must point at the same
subvolume, otherwise the mount will fail.</p>


<p style="margin-left:11%;"><b>thread_pool=&lt;number&gt;</b></p>

<p style="margin-left:22%;">(default: min(NRCPUS + 2, 8)
)</p>

<p style="margin-left:22%; margin-top: 1em">The number of
worker threads to start. NRCPUS is number of on&minus;line
CPUs detected at the time of mount. Small number leads to
less parallelism in processing data and metadata, higher
numbers could lead to a performance hit due to increased
locking contention, process scheduling, cache&minus;line
bouncing or costly data transfers between local CPU
memories.</p>

<p style="margin-left:11%;"><b>treelog, notreelog</b></p>

<p style="margin-left:22%;">(default: on)</p>

<p style="margin-left:22%; margin-top: 1em">Enable the tree
logging used for <i>fsync</i> and <i>O_SYNC</i> writes. The
tree log stores changes without the need of a full
filesystem sync. The log operations are flushed at sync and
transaction commit. If the system crashes between two such
syncs, the pending tree log operations are replayed during
mount.</p>


<p style="margin-left:22%; margin-top: 1em"><b>WARNING:</b></p>

<p style="margin-left:26%;">Currently, the tree log is
replayed even with a read&minus;only mount! To disable that
behaviour, also mount with <i>nologreplay</i>.</p>

<p style="margin-left:22%; margin-top: 1em">The tree log
could contain new files/directories, these would not exist
on a mounted filesystem if the log is not replayed.</p>

<p style="margin-left:11%;"><b>usebackuproot</b></p>

<p style="margin-left:22%;">(since: 4.6, default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Enable
autorecovery attempts if a bad tree root is found at mount
time. Currently this scans a backup list of several previous
tree roots and tries to use the first readable. This can be
used with read&minus;only mounts as well.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">This option has replaced
<i>recovery</i>.</p>


<p style="margin-left:11%;"><b>user_subvol_rm_allowed</b></p>

<p style="margin-left:22%;">(default: off)</p>

<p style="margin-left:22%; margin-top: 1em">Allow
subvolumes to be deleted by their respective owner.
Otherwise, only the root user can do that.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">Historically, any user could
create a snapshot even if he was not owner of the source
subvolume, the subvolume deletion has been restricted for
that reason. The subvolume creation has been restricted but
this mount option is still required. This is a usability
issue. Since 4.18, the <b>rmdir(2)</b> syscall can delete an
empty subvolume just like an ordinary directory. Whether
this is possible can be detected at runtime, see
<i>rmdir_subvol</i> feature in <i>FILESYSTEM
FEATURES</i>.</p>

<p style="margin-left:11%; margin-top: 1em"><b>DEPRECATED
MOUNT OPTIONS</b> <br>
List of mount options that have been removed, kept for
backward compatibility. <b><br>
recovery</b></p>

<p style="margin-left:22%;">(since: 3.2, default: off,
deprecated since: 4.5)</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">This option has been replaced
by <i>usebackuproot</i> and should not be used but will work
on 4.5+ kernels.</p>

<p style="margin-left:11%;"><b>inode_cache,
noinode_cache</b></p>

<p style="margin-left:22%;">(removed in: 5.11, since: 3.0,
default: off)</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">The functionality has been
removed in 5.11, any stale data created by previous use of
the <i>inode_cache</i> option can be removed by <b>btrfs
check &minus;&minus;clear&minus;ino&minus;cache</b>.</p>

<p style="margin-left:11%; margin-top: 1em"><b>NOTES ON
GENERIC MOUNT OPTIONS</b> <br>
Some of the general mount options from <b>mount(8)</b> that
affect BTRFS and are worth mentioning. <b><br>
noatime</b></p>

<p style="margin-left:22%;">under read intensive
work&minus;loads, specifying <i>noatime</i> significantly
improves performance because no new access time information
needs to be written. Without this option, the default is
<i>relatime</i>, which only reduces the number of inode
atime updates in comparison to the traditional
<i>strictatime</i>. The worst case for atime updates under
<i>relatime</i> occurs when many files are read whose atime
is older than 24 h and which are freshly snapshotted. In
that case the atime is updated and COW happens &minus; for
each file &minus; in bulk. See also
<i>https://lwn.net/Articles/499293/</i> &minus; <i>Atime and
btrfs: a bad combination? (LWN,
2012&minus;05&minus;31)</i>.</p>

<p style="margin-left:22%; margin-top: 1em">Note that
<i>noatime</i> may break applications that rely on atime
uptimes like the venerable Mutt (unless you use maildir
mailboxes).</p>

<h2>FILESYSTEM FEATURES
<a name="FILESYSTEM FEATURES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The basic set
of filesystem features gets extended over time. The backward
compatibility is maintained and the features are optional,
need to be explicitly asked for so accidental use will not
create incompatibilities.</p>

<p style="margin-left:11%; margin-top: 1em">There are
several classes and the respective tools to manage the
features: <b><br>
at mkfs time only</b></p>

<p style="margin-left:22%;">This is namely for core
structures, like the b&minus;tree nodesize or checksum
algorithm, see <i>mkfs.btrfs(8)</i> for more details.</p>

<p style="margin-left:11%;"><b>after mkfs, on an unmounted
filesystem</b></p>

<p style="margin-left:22%;">Features that may optimize
internal structures or add new structures to support new
functionality, see <i>btrfstune(8)</i>. The command <b>btrfs
inspect&minus;internal dump&minus;super /dev/sdx</b> will
dump a superblock, you can map the value of
<i>incompat_flags</i> to the features listed below</p>

<p style="margin-left:11%;"><b>after mkfs, on a mounted
filesystem</b></p>

<p style="margin-left:22%;">The features of a filesystem
(with a given UUID) are listed in
<i>/sys/fs/btrfs/UUID/features/</i>, one file per feature.
The status is stored inside the file. The value <i>1</i> is
for enabled and active, while <i>0</i> means the feature was
enabled at mount time but turned off afterwards.</p>

<p style="margin-left:22%; margin-top: 1em">Whether a
particular feature can be turned on a mounted filesystem can
be found in the directory <i>/sys/fs/btrfs/features/</i>,
one file per feature. The value <i>1</i> means the feature
can be enabled.</p>

<p style="margin-left:11%; margin-top: 1em">List of
features (see also <i>mkfs.btrfs(8)</i> section
<i>FILESYSTEM FEATURES</i>): <b><br>
big_metadata</b></p>

<p style="margin-left:22%;">(since: 3.4)</p>

<p style="margin-left:22%; margin-top: 1em">the filesystem
uses <i>nodesize</i> for metadata blocks, this can be bigger
than the page size</p>

<p style="margin-left:11%;"><b>block_group_tree</b></p>

<p style="margin-left:22%;">(since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">block group
item representation using a dedicated b&minus;tree, this can
greatly reduce mount time for large filesystems</p>

<p style="margin-left:11%;"><b>compress_lzo</b></p>

<p style="margin-left:22%;">(since: 2.6.38)</p>

<p style="margin-left:22%; margin-top: 1em">the <i>lzo</i>
compression has been used on the filesystem, either as a
mount option or via <b>btrfs filesystem defrag</b>.</p>

<p style="margin-left:11%;"><b>compress_zstd</b></p>

<p style="margin-left:22%;">(since: 4.14)</p>

<p style="margin-left:22%; margin-top: 1em">the <i>zstd</i>
compression has been used on the filesystem, either as a
mount option or via <b>btrfs filesystem defrag</b>.</p>

<p style="margin-left:11%;"><b>default_subvol</b></p>

<p style="margin-left:22%;">(since: 2.6.34)</p>

<p style="margin-left:22%; margin-top: 1em">the default
subvolume has been set on the filesystem</p>

<p style="margin-left:11%;"><b>extended_iref</b></p>

<p style="margin-left:22%;">(since: 3.7)</p>

<p style="margin-left:22%; margin-top: 1em">increased
hardlink limit per file in a directory to 65536, older
kernels supported a varying number of hardlinks depending on
the sum of all file name sizes that can be stored into one
metadata block</p>

<p style="margin-left:11%;"><b>free_space_tree</b></p>

<p style="margin-left:22%;">(since: 4.5)</p>

<p style="margin-left:22%; margin-top: 1em">free space
representation using a dedicated b&minus;tree, successor of
v1 space cache</p>

<p style="margin-left:11%;"><b>metadata_uuid</b></p>

<p style="margin-left:22%;">(since: 5.0)</p>

<p style="margin-left:22%; margin-top: 1em">the main
filesystem UUID is the metadata_uuid, which stores the new
UUID only in the superblock while all metadata blocks still
have the UUID set at mkfs time, see <i>btrfstune(8)</i> for
more</p>

<p style="margin-left:11%;"><b>mixed_backref</b></p>

<p style="margin-left:22%;">(since: 2.6.31)</p>

<p style="margin-left:22%; margin-top: 1em">the last major
disk format change, improved backreferences, now default</p>

<p style="margin-left:11%;"><b>mixed_groups</b></p>

<p style="margin-left:22%;">(since: 2.6.37)</p>

<p style="margin-left:22%; margin-top: 1em">mixed data and
metadata block groups, i.e. the data and metadata are not
separated and occupy the same block groups, this mode is
suitable for small volumes as there are no constraints how
the remaining space should be used (compared to the split
mode, where empty metadata space cannot be used for data and
vice versa)</p>

<p style="margin-left:22%; margin-top: 1em">on the other
hand, the final layout is quite unpredictable and possibly
highly fragmented, which means worse performance</p>

<p style="margin-left:11%;"><b>no_holes</b></p>

<p style="margin-left:22%;">(since: 3.14)</p>

<p style="margin-left:22%; margin-top: 1em">improved
representation of file extents where holes are not
explicitly stored as an extent, saves a few percent of
metadata if sparse files are used</p>

<p style="margin-left:11%;"><b>raid1c34</b></p>

<p style="margin-left:22%;">(since: 5.5)</p>

<p style="margin-left:22%; margin-top: 1em">extended RAID1
mode with copies on 3 or 4 devices respectively</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="9%">


<p><b>RAID56</b></p></td>
<td width="2%"></td>
<td width="18%">


<p>(since: 3.9)</p></td>
<td width="60%">
</td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">the filesystem
contains or contained a RAID56 profile of block groups</p>

<p style="margin-left:11%;"><b>rmdir_subvol</b></p>

<p style="margin-left:22%;">(since: 4.18)</p>

<p style="margin-left:22%; margin-top: 1em">indicate that
<b>rmdir(2)</b> syscall can delete an empty subvolume just
like an ordinary directory. Note that this feature only
depends on the kernel version.</p>

<p style="margin-left:11%;"><b>skinny_metadata</b></p>

<p style="margin-left:22%;">(since: 3.10)</p>


<p style="margin-left:22%; margin-top: 1em">reduced&minus;size
metadata for extent references, saves a few percent of
metadata</p>

<p style="margin-left:11%;"><b>send_stream_version</b></p>

<p style="margin-left:22%;">(since: 5.10)</p>

<p style="margin-left:22%; margin-top: 1em">number of the
highest supported send stream version</p>

<p style="margin-left:11%;"><b>supported_checksums</b></p>

<p style="margin-left:22%;">(since: 5.5)</p>

<p style="margin-left:22%; margin-top: 1em">list of
checksum algorithms supported by the kernel module, the
respective modules or built&minus;in implementing the
algorithms need to be present to mount the filesystem, see
<i>CHECKSUM ALGORITHMS</i></p>


<p style="margin-left:11%;"><b>supported_sectorsizes</b></p>

<p style="margin-left:22%;">(since: 5.13)</p>

<p style="margin-left:22%; margin-top: 1em">list of values
that are accepted as sector sizes (<b>mkfs.btrfs
&minus;&minus;sectorsize</b>) by the running kernel</p>


<p style="margin-left:11%;"><b>supported_rescue_options</b></p>

<p style="margin-left:22%;">(since: 5.11)</p>

<p style="margin-left:22%; margin-top: 1em">list of values
for the mount option <i>rescue</i> that are supported by the
running kernel, see <i>btrfs(5)</i></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="7%">


<p><b>zoned</b></p></td>
<td width="4%"></td>
<td width="20%">


<p>(since: 5.12)</p></td>
<td width="58%">
</td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">zoned mode is
allocation/write friendly to host&minus;managed zoned
devices, allocation space is partitioned into
fixed&minus;size zones that must be updated sequentially,
see <i>ZONED MODE</i></p>

<h2>SWAPFILE SUPPORT
<a name="SWAPFILE SUPPORT"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">A swapfile,
when active, is a file&minus;backed swap area. It is
supported since kernel 5.0. Use <b>swapon(8)</b> to activate
it, until then (respectively again after deactivating it
with <b>swapoff(8)</b>) it's just a normal file (with
NODATACOW set), for which the special restrictions for
active swapfiles don't apply.</p>

<p style="margin-left:11%; margin-top: 1em">There are some
limitations of the implementation in BTRFS and Linux swap
subsystem:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">filesystem &minus; must be only
single device</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>filesystem &minus; must have only <i>single</i> data
profile</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>subvolume &minus; cannot be snapshotted if it contains
any active swapfiles</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>swapfile &minus; must be preallocated (i.e. no
holes)</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>swapfile &minus; must be NODATACOW (i.e. also NODATASUM,
no compression)</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">The limitations
come namely from the COW&minus;based design and mapping
layer of blocks that allows the advanced features like
relocation and multi&minus;device filesystems. However, the
swap subsystem expects simpler mapping and no background
changes of the file block location once they've been
assigned to swap.</p>

<p style="margin-left:11%; margin-top: 1em">With active
swapfiles, the following whole&minus;filesystem operations
will skip swapfile extents or may fail:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">balance &minus; block groups
with extents of any active swapfiles are skipped and
reported, the rest will be processed normally</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>resize grow &minus; unaffected</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>resize shrink &minus; works as long as the extents of
any active swapfiles are outside of the shrunk range</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>device add &minus; if the new devices do not interfere
with any already active swapfiles this operation will work,
though no new swapfile can be activated afterwards</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>device delete &minus; if the device has been added as
above, it can be also deleted</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>device replace &minus; ditto</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">When there are
no active swapfiles and a whole&minus;filesystem exclusive
operation is running (e.g. balance, device delete, shrink),
the swapfiles cannot be temporarily activated. The operation
must finish first.</p>

<p style="margin-left:11%; margin-top: 1em">To create and
activate a swapfile run the following commands:</p>

<pre style="margin-left:15%; margin-top: 1em"># truncate &minus;s 0 swapfile
# chattr +C swapfile
# fallocate &minus;l 2G swapfile
# chmod 0600 swapfile
# mkswap swapfile
# swapon swapfile</pre>


<p style="margin-left:11%; margin-top: 1em">Since version
6.1 it's possible to create the swapfile in a single command
(except the activation):</p>

<pre style="margin-left:15%; margin-top: 1em"># btrfs filesystem mkswapfile &minus;&minus;size 2G swapfile
# swapon swapfile</pre>


<p style="margin-left:11%; margin-top: 1em">Please note
that the UUID returned by the <i>mkswap</i> utility
identifies the swap &quot;filesystem&quot; and because it's
stored in a file, it's not generally visible and usable as
an identifier unlike if it was on a block device.</p>

<p style="margin-left:11%; margin-top: 1em">Once activated
the file will appear in <i>/proc/swaps</i>:</p>

<pre style="margin-left:15%; margin-top: 1em"># cat /proc/swaps
Filename          Type          Size           Used      Priority
/path/swapfile    file          2097152        0         &minus;2</pre>


<p style="margin-left:11%; margin-top: 1em">The swapfile
can be created as one&minus;time operation or, once properly
created, activated on each boot by the <b>swapon
&minus;a</b> command (usually started by the service
manager). Add the following entry to <i>/etc/fstab</i>,
assuming the filesystem that provides the <i>/path</i> has
been already mounted at this point. Additional mount options
relevant for the swapfile can be set too (like priority, not
the BTRFS mount options).</p>

<pre style="margin-left:15%; margin-top: 1em">/path/swapfile        none        swap        defaults      0 0</pre>


<p style="margin-left:11%; margin-top: 1em">From now on the
subvolume with the active swapfile cannot be snapshotted
until the swapfile is deactivated again by <b>swapoff</b>.
Then the swapfile is a regular file and the subvolume can be
snapshotted again, though this would prevent another
activation any swapfile that has been snapshotted. New
swapfiles (not snapshotted) can be created and
activated.</p>

<p style="margin-left:11%; margin-top: 1em">Otherwise, an
inactive swapfile does not affect the containing subvolume.
Activation creates a temporary in&minus;memory status and
prevents some file operations, but is not stored
permanently.</p>

<h2>HIBERNATION
<a name="HIBERNATION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">A swapfile can
be used for hibernation but it's not straightforward. Before
hibernation a resume offset must be written to file
<i>/sys/power/resume_offset</i> or the kernel command line
parameter <i>resume_offset</i> must be set.</p>

<p style="margin-left:11%; margin-top: 1em">The value is
the physical offset on the device. Note that <b>this is not
the same value that filefrag prints as physical
offset!</b></p>

<p style="margin-left:11%; margin-top: 1em">Btrfs
filesystem uses mapping between logical and physical
addresses but here the physical can still map to one or more
device&minus;specific physical block addresses. It's the
device&minus;specific physical offset that is suitable as
resume offset.</p>

<p style="margin-left:11%; margin-top: 1em">Since version
6.1 there's a command <b>btrfs inspect&minus;internal
map&minus;swapfile</b> that will print the device physical
offset and the adjusted value for
<i>/sys/power/resume_offset</i>. Note that the value is
divided by page size, i.e. it's not the offset itself.</p>

<pre style="margin-left:15%; margin-top: 1em"># btrfs filesystem mkswapfile swapfile
# btrfs inspect&minus;internal map&minus;swapfile swapfile
Physical start: 811511726080
Resume offset:     198122980</pre>


<p style="margin-left:11%; margin-top: 1em">For scripting
and convenience the option <i>&minus;r</i> will print just
the offset:</p>

<pre style="margin-left:15%; margin-top: 1em"># btrfs inspect&minus;internal map&minus;swapfile &minus;r swapfile
198122980</pre>


<p style="margin-left:11%; margin-top: 1em">The command
<i>map&minus;swapfile</i> also verifies all the
requirements, i.e. no holes, single device, etc.</p>

<h2>TROUBLESHOOTING
<a name="TROUBLESHOOTING"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">If the swapfile
activation fails please verify that you followed all the
steps above or check the system log (e.g. <b>dmesg</b> or
<b>journalctl</b>) for more information.</p>

<p style="margin-left:11%; margin-top: 1em">Notably, the
<b>swapon</b> utility exits with a message that does not say
what failed:</p>

<pre style="margin-left:15%; margin-top: 1em"># swapon /path/swapfile
swapon: /path/swapfile: swapon failed: Invalid argument</pre>


<p style="margin-left:11%; margin-top: 1em">The specific
reason is likely to be printed to the system log by the
btrfs module:</p>

<pre style="margin-left:15%; margin-top: 1em"># journalctl &minus;t kernel | grep swapfile
kernel: BTRFS warning (device sda): swapfile must have single data profile</pre>


<h2>CHECKSUM ALGORITHMS
<a name="CHECKSUM ALGORITHMS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Data and
metadata are checksummed by default, the checksum is
calculated before write and verified after reading the
blocks from devices. The whole metadata block has a checksum
stored inline in the b&minus;tree node header, each data
block has a detached checksum stored in the checksum
tree.</p>

<p style="margin-left:11%; margin-top: 1em">There are
several checksum algorithms supported. The default and
backward compatible is <i>crc32c</i>. Since kernel 5.5 there
are three more with different characteristics and
trade&minus;offs regarding speed and strength. The following
list may help you to decide which one to select. <b><br>
CRC32C (32bit digest)</b></p>

<p style="margin-left:22%;">default, best backward
compatibility, very fast, modern CPUs have
instruction&minus;level support, not
collision&minus;resistant but still good error detection
capabilities</p>

<p style="margin-left:11%;"><b>XXHASH (64bit
digest)</b></p>

<p style="margin-left:22%;">can be used as CRC32C
successor, very fast, optimized for modern CPUs utilizing
instruction pipelining, good collision resistance and error
detection</p>

<p style="margin-left:11%;"><b>SHA256 (256bit
digest)</b></p>

<p style="margin-left:22%;">a cryptographic&minus;strength
hash, relatively slow but with possible CPU instruction
acceleration or specialized hardware cards, FIPS certified
and in wide use</p>

<p style="margin-left:11%;"><b>BLAKE2b (256bit
digest)</b></p>

<p style="margin-left:22%;">a cryptographic&minus;strength
hash, relatively fast with possible CPU acceleration using
SIMD extensions, not standardized but based on BLAKE which
was a SHA3 finalist, in wide use, the algorithm used is
BLAKE2b&minus;256 that's optimized for 64bit platforms</p>

<p style="margin-left:11%; margin-top: 1em">The <i>digest
size</i> affects overall size of data block checksums stored
in the filesystem. The metadata blocks have a fixed area up
to 256 bits (32 bytes), so there's no increase. Each data
block has a separate checksum stored, with additional
overhead of the b&minus;tree leaves.</p>

<p style="margin-left:11%; margin-top: 1em">Approximate
relative performance of the algorithms, measured against
CRC32C using reference software implementations on a 3.5GHz
intel CPU:</p>


<p align="center" style="margin-top: 1em"><img src="grohtml-35794611.png" alt="Image grohtml-35794611.png"></p>

<p style="margin-left:11%;">Many kernels are configured
with SHA256 as built&minus;in and not as a module. The
accelerated versions are however provided by the modules and
must be loaded explicitly (<b>modprobe sha256</b>) before
mounting the filesystem to make use of them. You can check
in <i>/sys/fs/btrfs/FSID/checksum</i> which one is used. If
you see <i>sha256&minus;generic</i>, then you may want to
unmount and mount the filesystem again, changing that on a
mounted filesystem is not possible. Check the file
<i>/proc/crypto</i>, when the implementation is
built&minus;in, you'd find</p>

<pre style="margin-left:15%; margin-top: 1em">name         : sha256
driver       : sha256&minus;generic
module       : kernel
priority     : 100
...</pre>


<p style="margin-left:11%; margin-top: 1em">while
accelerated implementation is e.g.</p>

<pre style="margin-left:15%; margin-top: 1em">name         : sha256
driver       : sha256&minus;avx2
module       : sha256_ssse3
priority     : 170
...</pre>


<h2>COMPRESSION
<a name="COMPRESSION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Btrfs supports
transparent file compression. There are three algorithms
available: ZLIB, LZO and ZSTD (since v4.14), with various
levels. The compression happens on the level of file extents
and the algorithm is selected by file property, mount option
or by a defrag command. You can have a single btrfs mount
point that has some files that are uncompressed, some that
are compressed with LZO, some with ZLIB, for instance
(though you may not want it that way, it is supported).</p>

<p style="margin-left:11%; margin-top: 1em">Once the
compression is set, all newly written data will be
compressed, i.e. existing data are untouched. Data are split
into smaller chunks (128KiB) before compression to make
random rewrites possible without a high performance hit. Due
to the increased number of extents the metadata consumption
is higher. The chunks are compressed in parallel.</p>

<p style="margin-left:11%; margin-top: 1em">The algorithms
can be characterized as follows regarding the speed/ratio
trade&minus;offs:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p><b>ZLIB</b></p></td>
<td width="2%"></td>
<td width="75%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>slower, higher compression ratio</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>levels: 1 to 9, mapped directly, default level is 3</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>good backward compatibility</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p><b>LZO</b></p></td>
<td width="2%"></td>
<td width="75%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>faster compression and decompression than ZLIB, worse
compression ratio, designed to be fast</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>no levels</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>good backward compatibility</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p><b>ZSTD</b></p></td>
<td width="2%"></td>
<td width="75%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>compression comparable to ZLIB with higher
compression/decompression speeds and different ratio</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>levels: 1 to 15, mapped directly (higher levels are not
available)</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="12%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p>since 4.14, levels since 5.1</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">The differences
depend on the actual data set and cannot be expressed by a
single number or recommendation. Higher levels consume more
CPU time and may not bring a significant improvement, lower
levels are close to real time.</p>

<h2>HOW TO ENABLE COMPRESSION
<a name="HOW TO ENABLE COMPRESSION"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Typically the
compression can be enabled on the whole filesystem,
specified for the mount point. Note that the compression
mount options are shared among all mounts of the same
filesystem, either bind mounts or subvolume mounts. Please
refer to section <i>MOUNT OPTIONS</i>.</p>

<pre style="margin-left:15%; margin-top: 1em">$ mount &minus;o compress=zstd /dev/sdx /mnt</pre>


<p style="margin-left:11%; margin-top: 1em">This will
enable the <b>zstd</b> algorithm on the default level (which
is 3). The level can be specified manually too like
<b>zstd:3</b>. Higher levels compress better at the cost of
time. This in turn may cause increased write latency, low
levels are suitable for real&minus;time compression and on
reasonably fast CPU don't cause noticeable performance
drops.</p>

<pre style="margin-left:15%; margin-top: 1em">$ btrfs filesystem defrag &minus;czstd file</pre>


<p style="margin-left:11%; margin-top: 1em">The command
above will start defragmentation of the whole <i>file</i>
and apply the compression, regardless of the mount option.
(Note: specifying level is not yet implemented). The
compression algorithm is not persistent and applies only to
the defragmentation command, for any other writes other
compression settings apply.</p>

<p style="margin-left:11%; margin-top: 1em">Persistent
settings on a per&minus;file basis can be set in two
ways:</p>

<pre style="margin-left:15%; margin-top: 1em">$ chattr +c file
$ btrfs property set file compression zstd</pre>


<p style="margin-left:11%; margin-top: 1em">The first
command is using legacy interface of file attributes
inherited from ext2 filesystem and is not flexible, so by
default the <i>zlib</i> compression is set. The other
command sets a property on the file with the given
algorithm. (Note: setting level that way is not yet
implemented.)</p>

<h2>COMPRESSION LEVELS
<a name="COMPRESSION LEVELS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The level
support of ZLIB has been added in v4.14, LZO does not
support levels (the kernel implementation provides only
one), ZSTD level support has been added in v5.1.</p>

<p style="margin-left:11%; margin-top: 1em">There are 9
levels of ZLIB supported (1 to 9), mapping 1:1 from the
mount option to the algorithm defined level. The default is
level 3, which provides the reasonably good compression
ratio and is still reasonably fast. The difference in
compression gain of levels 7, 8 and 9 is comparable but the
higher levels take longer.</p>

<p style="margin-left:11%; margin-top: 1em">The ZSTD
support includes levels 1 to 15, a subset of full range of
what ZSTD provides. Levels 1&minus;3 are real&minus;time,
4&minus;8 slower with improved compression and 9&minus;15
try even harder though the resulting size may not be
significantly improved.</p>

<p style="margin-left:11%; margin-top: 1em">Level 0 always
maps to the default. The compression level does not affect
compatibility.</p>

<h2>INCOMPRESSIBLE DATA
<a name="INCOMPRESSIBLE DATA"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Files with
already compressed data or with data that won't compress
well with the CPU and memory constraints of the kernel
implementations are using a simple decision logic. If the
first portion of data being compressed is not smaller than
the original, the compression of the file is disabled
&minus;&minus; unless the filesystem is mounted with
<i>compress&minus;force</i>. In that case compression will
always be attempted on the file only to be later discarded.
This is not optimal and subject to optimizations and further
development.</p>

<p style="margin-left:11%; margin-top: 1em">If a file is
identified as incompressible, a flag is set
(<i>NOCOMPRESS</i>) and it's sticky. On that file
compression won't be performed unless forced. The flag can
be also set by <b>chattr +m</b> (since e2fsprogs 1.46.2) or
by properties with value <i>no</i> or <i>none</i>. Empty
value will reset it to the default that's currently
applicable on the mounted filesystem.</p>

<p style="margin-left:11%; margin-top: 1em">There are two
ways to detect incompressible data:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">actual compression attempt
&minus; data are compressed, if the result is not smaller,
it's discarded, so this depends on the algorithm and
level</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>pre&minus;compression heuristics &minus; a quick
statistical evaluation on the data is performed and based on
the result either compression is performed or skipped, the
NOCOMPRESS bit is not set just by the heuristic, only if the
compression algorithm does not make an improvement</p></td></tr>
</table>

<pre style="margin-left:15%; margin-top: 1em">$ lsattr file
&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;&minus;m file</pre>


<p style="margin-left:11%; margin-top: 1em">Using the
forcing compression is not recommended, the heuristics are
supposed to decide that and compression algorithms
internally detect incompressible data too.</p>

<h2>PRE-COMPRESSION HEURISTICS
<a name="PRE-COMPRESSION HEURISTICS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The heuristics
aim to do a few quick statistical tests on the compressed
data in order to avoid probably costly compression that
would turn out to be inefficient. Compression algorithms
could have internal detection of incompressible data too but
this leads to more overhead as the compression is done in
another thread and has to write the data anyway. The
heuristic is read&minus;only and can utilize cached
memory.</p>

<p style="margin-left:11%; margin-top: 1em">The tests
performed based on the following: data sampling, long
repeated pattern detection, byte frequency, Shannon
entropy.</p>

<h2>COMPATIBILITY
<a name="COMPATIBILITY"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Compression is
done using the COW mechanism so it's incompatible with
<i>nodatacow</i>. Direct IO works on compressed files but
will fall back to buffered writes and leads to
recompression. Currently <i>nodatasum</i> and compression
don't work together.</p>

<p style="margin-left:11%; margin-top: 1em">The compression
algorithms have been added over time so the version
compatibility should be also considered, together with other
tools that may access the compressed data like
bootloaders.</p>

<h2>SYSFS INTERFACE
<a name="SYSFS INTERFACE"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Btrfs has a
sysfs interface to provide extra knobs.</p>

<p style="margin-left:11%; margin-top: 1em">The top level
path is <i>/sys/fs/btrfs/</i>, and the main directory layout
is the following:</p>


<p align="center" style="margin-top: 1em"><img src="grohtml-35794612.png" alt="Image grohtml-35794612.png"></p>

<p style="margin-left:11%;">For
<i>/sys/fs/btrfs/features/</i> directory, each file means a
supported feature for the current kernel.</p>

<p style="margin-left:11%; margin-top: 1em">For
<i>/sys/fs/btrfs/&lt;UUID&gt;/features/</i> directory, each
file means an enabled feature for the mounted
filesystem.</p>

<p style="margin-left:11%; margin-top: 1em">The features
shares the same name in section <i>FILESYSTEM
FEATURES</i>.</p>

<p style="margin-left:11%; margin-top: 1em">Files in
<i>/sys/fs/btrfs/&lt;UUID&gt;/</i> directory are: <b><br>
bg_reclaim_threshold</b></p>

<p style="margin-left:22%;">(RW, since: 5.19)</p>

<p style="margin-left:22%; margin-top: 1em">Used space
percentage of total device space to start auto block group
claim. Mostly for zoned devices.</p>

<p style="margin-left:11%;"><b>checksum</b></p>

<p style="margin-left:22%;">(RO, since: 5.5)</p>

<p style="margin-left:22%; margin-top: 1em">The checksum
used for the mounted filesystem. This includes both the
checksum type (see section <i>CHECKSUM ALGORITHMS</i>) and
the implemented driver (mostly shows if it's hardware
accelerated).</p>

<p style="margin-left:11%;"><b>clone_alignment</b></p>

<p style="margin-left:22%;">(RO, since: 3.16)</p>

<p style="margin-left:22%; margin-top: 1em">The bytes
alignment for <i>clone</i> and <i>dedupe</i> ioctls.</p>

<p style="margin-left:11%;"><b>commit_stats</b></p>

<p style="margin-left:22%;">(RW, since: 6.0)</p>

<p style="margin-left:22%; margin-top: 1em">The performance
statistics for btrfs transaction commit. Mostly for debug
purposes.</p>

<p style="margin-left:22%; margin-top: 1em">Writing into
this file will reset the maximum commit duration to the
input value.</p>

<p style="margin-left:11%;"><b>exclusive_operation</b></p>

<p style="margin-left:22%;">(RO, since: 5.10)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
running exclusive operation. Check section <i>FILESYSTEM
EXCLUSIVE OPERATIONS</i> for details.</p>

<p style="margin-left:11%;"><b>generation</b></p>

<p style="margin-left:22%;">(RO, since: 5.11)</p>

<p style="margin-left:22%; margin-top: 1em">Show the
generation of the mounted filesystem.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="7%">


<p><b>label</b></p></td>
<td width="4%"></td>
<td width="26%">


<p>(RW, since: 3.14)</p></td>
<td width="52%">
</td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">Show the
current label of the mounted filesystem.</p>

<p style="margin-left:11%;"><b>metadata_uuid</b></p>

<p style="margin-left:22%;">(RO, since: 5.0)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
metadata uuid of the mounted filesystem. Check
<i>metadata_uuid</i> feature for more details.</p>

<p style="margin-left:11%;"><b>nodesize</b></p>

<p style="margin-left:22%;">(RO, since: 3.14)</p>

<p style="margin-left:22%; margin-top: 1em">Show the
nodesize of the mounted filesystem.</p>

<p style="margin-left:11%;"><b>quota_override</b></p>

<p style="margin-left:22%;">(RW, since: 4.13)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
current quota override status. 0 means no quota override. 1
means quota override, quota can ignore the existing limit
settings.</p>

<p style="margin-left:11%;"><b>read_policy</b></p>

<p style="margin-left:22%;">(RW, since: 5.11)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
current balance policy for reads. Currently only
&quot;pid&quot; (balance using pid value) is supported.</p>

<p style="margin-left:11%;"><b>sectorsize</b></p>

<p style="margin-left:22%;">(RO, since: 3.14)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
sectorsize of the mounted filesystem.</p>

<p style="margin-left:11%; margin-top: 1em">Files and
directories in <i>/sys/fs/btrfs/&lt;UUID&gt;/allocations</i>
directory are: <b><br>
global_rsv_reserved</b></p>

<p style="margin-left:22%;">(RO, since: 3.14)</p>

<p style="margin-left:22%; margin-top: 1em">The used bytes
of the global reservation.</p>

<p style="margin-left:11%;"><b>global_rsv_size</b></p>

<p style="margin-left:22%;">(RO, since: 3.14)</p>

<p style="margin-left:22%; margin-top: 1em">The total size
of the global reservation.</p>

<p style="margin-left:11%;"><i>data/</i><b>,</b>
<i>metadata/</i> <b>and</b> <i>system/</i>
<b>directories</b></p>

<p style="margin-left:22%;">(RO, since: 5.14)</p>

<p style="margin-left:22%; margin-top: 1em">Space info
accounting for the 3 chunk types. Mostly for debug
purposes.</p>

<p style="margin-left:11%; margin-top: 1em">Files in
<i>/sys/fs/btrfs/&lt;UUID&gt;/allocations/{data,metadata,system}</i>
directory are: <b><br>
bg_reclaim_threshold</b></p>

<p style="margin-left:22%;">(RW, since: 5.19)</p>

<p style="margin-left:22%; margin-top: 1em">Reclaimable
space percentage of block group's size (excluding
permanently unusable space) to reclaim the block group. Can
be used on regular or zoned devices.</p>

<p style="margin-left:11%;"><b>chunk_size</b></p>

<p style="margin-left:22%;">(RW, since: 6.0)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the chunk
size. Can be changed for data and metadata. Cannot be set
for zoned devices.</p>

<p style="margin-left:11%; margin-top: 1em">Files in
<i>/sys/fs/btrfs/&lt;UUID&gt;/devinfo/&lt;DEVID&gt;</i>
directory are: <b><br>
error_stats:</b></p>

<p style="margin-left:22%;">(RO, since: 5.14)</p>

<p style="margin-left:22%; margin-top: 1em">Shows all the
history error numbers of the device.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="7%">


<p><b>fsid:</b></p></td>
<td width="4%"></td>
<td width="26%">


<p>(RO, since: 5.17)</p></td>
<td width="52%">
</td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">Shows the fsid
which the device belongs to. It can be different than the
<i>&lt;UUID&gt;</i> if it's a seed device.</p>

<p style="margin-left:11%;"><b>in_fs_metadata</b></p>

<p style="margin-left:22%;">(RO, since: 5.6)</p>

<p style="margin-left:22%; margin-top: 1em">Shows whether
we have found the device. Should always be 1, as if this
turns to 0, the <i>&lt;DEVID&gt;</i> directory would get
removed automatically.</p>

<p style="margin-left:11%;"><b>missing</b></p>

<p style="margin-left:22%;">(RO, since: 5.6)</p>

<p style="margin-left:22%; margin-top: 1em">Shows whether
the device is missing.</p>

<p style="margin-left:11%;"><b>replace_target</b></p>

<p style="margin-left:22%;">(RO, since: 5.6)</p>

<p style="margin-left:22%; margin-top: 1em">Shows whether
the device is the replace target. If no dev&minus;replace is
running, this value should be 0.</p>

<p style="margin-left:11%;"><b>scrub_speed_max</b></p>

<p style="margin-left:22%;">(RW, since: 5.14)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the scrub
speed limit for this device. The unit is Bytes/s. 0 means no
limit.</p>

<p style="margin-left:11%;"><b>writeable</b></p>

<p style="margin-left:22%;">(RO, since: 5.6)</p>

<p style="margin-left:22%; margin-top: 1em">Show if the
device is writeable.</p>

<p style="margin-left:11%; margin-top: 1em">Files in
<i>/sys/fs/btrfs/&lt;UUID&gt;/qgroups/</i> directory are:
<b><br>
enabled</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows if qgroup
is enabled. Also, if qgroup is disabled, the <i>qgroups</i>
directory would be removed automatically.</p>

<p style="margin-left:11%;"><b>inconsistent</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows if the
qgroup numbers are inconsistent. If 1, it's recommended to
do a qgroup rescan.</p>


<p style="margin-left:11%;"><b>drop_subtree_threshold</b></p>

<p style="margin-left:22%;">(RW, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
subtree drop threshold to automatically mark qgroup
inconsistent.</p>

<p style="margin-left:22%; margin-top: 1em">When dropping
large subvolumes with qgroup enabled, there would be a huge
load for qgroup accounting. If we have a subtree whose level
is larger than or equal to this value, we will not trigger
qgroup account at all, but mark qgroup inconsistent to avoid
the huge workload.</p>

<p style="margin-left:22%; margin-top: 1em">Default value
is 8, where no subtree drop can trigger qgroup.</p>

<p style="margin-left:22%; margin-top: 1em">Lower value can
reduce qgroup workload, at the cost of extra qgroup rescan
to re&minus;calculate the numbers.</p>

<p style="margin-left:11%; margin-top: 1em">Files in
<i>/sys/fs/btrfs/&lt;UUID&gt;/&lt;LEVEL&gt;_&lt;ID&gt;/</i>
directory are: <b><br>
exclusive</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
exclusively owned bytes of the qgroup.</p>

<p style="margin-left:11%;"><b>limit_flags</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
numeric value of the limit flags. If 0, means no limit
implied.</p>

<p style="margin-left:11%;"><b>max_exclusive</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
limits on exclusively owned bytes.</p>

<p style="margin-left:11%;"><b>max_referenced</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
limits on referenced bytes.</p>

<p style="margin-left:11%;"><b>referenced</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
referenced bytes of the qgroup.</p>

<p style="margin-left:11%;"><b>rsv_data</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
reserved bytes for data.</p>

<p style="margin-left:11%;"><b>rsv_meta_pertrans</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
reserved bytes for per transaction metadata.</p>

<p style="margin-left:11%;"><b>rsv_meta_prealloc</b></p>

<p style="margin-left:22%;">(RO, since: 5.9)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
reserved bytes for preallocated metadata.</p>

<p style="margin-left:11%; margin-top: 1em">Files in
<i>/sys/fs/btrfs/&lt;UUID&gt;/discard/</i> directory are:
<b><br>
discardable_bytes</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows amount of
bytes that can be discarded in the async discard and
nodiscard mode.</p>

<p style="margin-left:11%;"><b>discardable_extents</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows number of
extents to be discarded in the async discard and nodiscard
mode.</p>


<p style="margin-left:11%;"><b>discard_bitmap_bytes</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows amount of
discarded bytes from data tracked as bitmaps.</p>


<p style="margin-left:11%;"><b>discard_extent_bytes</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows amount of
discarded extents from data tracked as bitmaps.</p>

<p style="margin-left:11%;"><b>discard_bytes_saved</b></p>

<p style="margin-left:22%;">(RO, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Shows the
amount of bytes that were reallocated without being
discarded.</p>

<p style="margin-left:11%;"><b>kbps_limit</b></p>

<p style="margin-left:22%;">(RW, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Tunable limit
of kilobytes per second issued as discard IO in the async
discard mode.</p>

<p style="margin-left:11%;"><b>iops_limit</b></p>

<p style="margin-left:22%;">(RW, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Tunable limit
of number of discard IO operations to be issued in the async
discard mode.</p>

<p style="margin-left:11%;"><b>max_discard_size</b></p>

<p style="margin-left:22%;">(RW, since: 6.1)</p>

<p style="margin-left:22%; margin-top: 1em">Tunable limit
for size of one IO discard request.</p>

<h2>FILESYSTEM EXCLUSIVE OPERATIONS
<a name="FILESYSTEM EXCLUSIVE OPERATIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">There are
several operations that affect the whole filesystem and
cannot be run in parallel. Attempt to start one while
another is running will fail (see exceptions below).</p>

<p style="margin-left:11%; margin-top: 1em">Since kernel
5.10 the currently running operation can be obtained from
<i>/sys/fs/UUID/exclusive_operation</i> with following
values and operations:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>balance</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>balance paused (since 5.17)</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>device add</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>device delete</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>device replace</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>resize</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>swapfile activate</p></td>
<td width="45%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="41%">


<p>none</p></td>
<td width="45%">
</td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">Enqueuing is
supported for several btrfs subcommands so they can be
started at once and then serialized.</p>

<p style="margin-left:11%; margin-top: 1em">There's an
exception when a paused balance allows to start a device add
operation as they don't really collide and this can be used
to add more space for the balance to finish.</p>

<h2>FILESYSTEM LIMITS
<a name="FILESYSTEM LIMITS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>maximum file
name length</b></p>

<p style="margin-left:22%;">255</p>

<p style="margin-left:22%; margin-top: 1em">This limit is
imposed by Linux VFS, the structures of BTRFS could store
larger file names.</p>

<p style="margin-left:11%;"><b>maximum symlink target
length</b></p>

<p style="margin-left:22%;">depends on the <i>nodesize</i>
value, for 4KiB it's 3949 bytes, for larger nodesize it's
4095 due to the system limit PATH_MAX</p>

<p style="margin-left:22%; margin-top: 1em">The symlink
target may not be a valid path, i.e. the path name
components can exceed the limits (NAME_MAX), there's no
content validation at <b>symlink(3)</b> creation.</p>

<p style="margin-left:11%;"><b>maximum number of
inodes</b></p>

<p style="margin-left:22%;">2 <small>64</small> but depends
on the available metadata space as the inodes are created
dynamically</p>

<p style="margin-left:22%; margin-top: 1em">Each subvolume
is an independent namespace of inodes and thus their
numbers, so the limit is per subvolume, not for the whole
filesystem.</p>

<p style="margin-left:11%;"><b>inode numbers</b></p>

<p style="margin-left:22%;">minimum number: 256 (for
subvolumes), regular files and directories: 257, maximum
number: (2:sup:<i>64</i> &minus; 256)</p>

<p style="margin-left:22%; margin-top: 1em">The inode
numbers that can be assigned to user created files are from
the whole 64bit space except first 256 and last 256 in that
range that are reserved for internal b&minus;tree
identifiers.</p>

<p style="margin-left:11%;"><b>maximum file length</b></p>

<p style="margin-left:22%;">inherent limit of BTRFS is 2
<small>64</small> (16 EiB) but the practical limit of Linux
VFS is 2 <small>63</small> (8 EiB)</p>

<p style="margin-left:11%;"><b>maximum number of
subvolumes</b></p>

<p style="margin-left:22%;">the subvolume ids can go up to
2 <small>48</small> but the number of actual subvolumes
depends on the available metadata space</p>

<p style="margin-left:22%; margin-top: 1em">The space
consumed by all subvolume metadata includes bookkeeping of
shared extents can be large (MiB, GiB). The range is not the
full 64bit range because of qgroups that use the upper 16
bits for another purposes.</p>

<p style="margin-left:11%;"><b>maximum number of hardlinks
of a file in a directory</b></p>

<p style="margin-left:22%;">65536 when the <i>extref</i>
feature is turned on during mkfs (default), roughly 100
otherwise</p>

<p style="margin-left:11%;"><b>minimum filesystem
size</b></p>

<p style="margin-left:22%;">the minimal size of each device
depends on the <i>mixed&minus;bg</i> feature, without that
(the default) it's about 109MiB, with mixed&minus;bg it's is
16MiB</p>

<h2>BOOTLOADER SUPPORT
<a name="BOOTLOADER SUPPORT"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">GRUB2
(<i>https://www.gnu.org/software/grub</i>) has the most
advanced support of booting from BTRFS with respect to
features.</p>

<p style="margin-left:11%; margin-top: 1em">U&minus;boot
(<i>https://www.denx.de/wiki/U&minus;Boot/</i>) has decent
support for booting but not all BTRFS features are
implemented, check the documentation.</p>

<p style="margin-left:11%; margin-top: 1em">In general, the
first 1MiB on each device is unused with the exception of
primary superblock that is on the offset 64KiB and spans
4KiB. The rest can be freely used by bootloaders or for
other system information. Note that booting from a
filesystem on <i>zoned device</i> is not supported.</p>

<h2>FILE ATTRIBUTES
<a name="FILE ATTRIBUTES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The btrfs
filesystem supports setting file attributes or flags. Note
there are old and new interfaces, with confusing names. The
following list should clarify that:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>attributes</i>: <b>chattr(1)</b> or <b>lsattr(1)</b>
utilities (the ioctls are FS_IOC_GETFLAGS and
FS_IOC_SETFLAGS), due to the ioctl names the attributes are
also called flags</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>xflags</i>: to distinguish from the previous, it's
extended flags, with tunable bits similar to the attributes
but extensible and new bits will be added in the future (the
ioctls are FS_IOC_FSGETXATTR and FS_IOC_FSSETXATTR but they
are not related to extended attributes that are also called
xattrs), there's no standard tool to change the bits,
there's support in <b>xfs_io(8)</b> as command <b>xfs_io
&minus;c chattr</b></p></td></tr>
</table>


<p style="margin-left:11%; margin-top: 1em"><b>Attributes</b></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em"><b>a</b></p></td>
<td width="10%"></td>
<td width="78%">


<p style="margin-top: 1em"><i>append only</i>, new writes
are always written at the end of the file</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>A</b></p></td>
<td width="10%"></td>
<td width="78%">


<p><i>no atime updates</i></p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>c</b></p></td>
<td width="10%"></td>
<td width="78%">


<p><i>compress data</i>, all data written after this
attribute is set will be compressed. Please note that
compression is also affected by the mount options or the
parent directory attributes.</p></td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">When set on a
directory, all newly created files will inherit this
attribute. This attribute cannot be set with 'm' at the same
time.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em"><b>C</b></p></td>
<td width="10%"></td>
<td width="78%">


<p style="margin-top: 1em"><i>no
copy&minus;on&minus;write</i>, file data modifications are
done in&minus;place</p></td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">When set on a
directory, all newly created files will inherit this
attribute.</p>


<p style="margin-left:22%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:26%;">Due to implementation
limitations, this flag can be set/unset only on empty
files.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em"><b>d</b></p></td>
<td width="10%"></td>
<td width="78%">


<p style="margin-top: 1em"><i>no dump</i>, makes sense with
3rd party tools like <b>dump(8)</b>, on BTRFS the attribute
can be set/unset but no other special handling is done</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>D</b></p></td>
<td width="10%"></td>
<td width="78%">


<p><i>synchronous directory updates</i>, for more details
search <b>open(2)</b> for <i>O_SYNC</i> and
<i>O_DSYNC</i></p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>i</b></p></td>
<td width="10%"></td>
<td width="78%">


<p><i>immutable</i>, no file data and metadata changes
allowed even to the root user as long as this attribute is
set (obviously the exception is unsetting the attribute)</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>m</b></p></td>
<td width="10%"></td>
<td width="78%">


<p><i>no compression</i>, permanently turn off compression
on the given file. Any compression mount options will not
affect this file. (<b>chattr</b> support added in
1.46.2)</p> </td></tr>
</table>

<p style="margin-left:22%; margin-top: 1em">When set on a
directory, all newly created files will inherit this
attribute. This attribute cannot be set with <i>c</i> at the
same time.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em"><b>S</b></p></td>
<td width="10%"></td>
<td width="78%">


<p style="margin-top: 1em"><i>synchronous updates</i>, for
more details search <b>open(2)</b> for <i>O_SYNC</i> and
<i>O_DSYNC</i></p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">No other
attributes are supported. For the complete list please refer
to the <b>chattr(1)</b> manual page.</p>

<p style="margin-left:11%; margin-top: 1em"><b>XFLAGS</b>
<br>
There's overlap of letters assigned to the bits with the
attributes, this list refers to what <b>xfs_io(8)</b>
provides:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em"><b>i</b></p></td>
<td width="10%"></td>
<td width="67%">


<p style="margin-top: 1em"><i>immutable</i>, same as the
attribute</p> </td>
<td width="11%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>a</b></p></td>
<td width="10%"></td>
<td width="67%">


<p><i>append only</i>, same as the attribute</p></td>
<td width="11%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>s</b></p></td>
<td width="10%"></td>
<td width="67%">


<p><i>synchronous updates</i>, same as the attribute
<i>S</i></p> </td>
<td width="11%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>A</b></p></td>
<td width="10%"></td>
<td width="67%">


<p><i>no atime updates</i>, same as the attribute</p></td>
<td width="11%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p><b>d</b></p></td>
<td width="10%"></td>
<td width="67%">


<p><i>no dump</i>, same as the attribute</p></td>
<td width="11%">
</td></tr>
</table>

<h2>ZONED MODE
<a name="ZONED MODE"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">Since version
5.12 btrfs supports so called <i>zoned mode</i>. This is a
special on&minus;disk format and allocation/write strategy
that's friendly to zoned devices. In short, a device is
partitioned into fixed&minus;size zones and each zone can be
updated by append&minus;only manner, or reset. As btrfs has
no fixed data structures, except the super blocks, the zoned
mode only requires block placement that follows the device
constraints. You can learn about the whole architecture at
<i>https://zonedstorage.io</i> .</p>

<p style="margin-left:11%; margin-top: 1em">The devices are
also called SMR/ZBC/ZNS, in <i>host&minus;managed</i> mode.
Note that there are devices that appear as non&minus;zoned
but actually are, this is <i>drive&minus;managed</i> and
using zoned mode won't help.</p>

<p style="margin-left:11%; margin-top: 1em">The zone size
depends on the device, typical sizes are 256MiB or 1GiB. In
general it must be a power of two. Emulated zoned devices
like <i>null_blk</i> allow to set various zone sizes.</p>


<p style="margin-left:11%; margin-top: 1em"><b>Requirements,
limitations</b></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">all devices must have the same
zone size</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>maximum zone size is 8GiB</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>minimum zone size is 4MiB</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>mixing zoned and non&minus;zoned devices is possible,
the zone writes are emulated, but this is namely for
testing</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><b>the super block is handled in a special way and is at
different</b></p> </td></tr>
</table>

<p style="margin-left:14%;"><b>locations than on a
non&minus;zoned filesystem:</b></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="25%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="72%">


<p>primary: 0B (and the next two zones)</p></td></tr>
<tr valign="top" align="left">
<td width="25%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="72%">


<p>secondary: 512GiB (and the next two zones)</p></td></tr>
<tr valign="top" align="left">
<td width="25%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="72%">


<p>tertiary: 4TiB (4096GiB, and the next two zones)</p></td></tr>
</table>


<p style="margin-left:11%; margin-top: 1em"><b>Incompatible
features</b> <br>
The main constraint of the zoned devices is lack of
in&minus;place update of the data. This is inherently
incompatible with some features:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">NODATACOW &minus; overwrite
in&minus;place, cannot create such files</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>fallocate &minus; preallocating space for in&minus;place
first write</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>mixed&minus;bg &minus; unordered writes to data and
metadata, fixing that means using separate data and metadata
block groups</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>booting &minus; the zone at offset 0 contains
superblock, resetting the zone would destroy the bootloader
data</p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">Initial support
lacks some features but they're planned:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">only single (data, metadata) and
DUP (metadata) profile is supported</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>fstrim &minus; due to dependency on free space cache
v1</p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Super
block</b> <br>
As said above, super block is handled in a special way. In
order to be crash safe, at least one zone in a known
location must contain a valid superblock. This is
implemented as a ring buffer in two consecutive zones,
starting from known offsets 0B, 512GiB and 4TiB.</p>

<p style="margin-left:11%; margin-top: 1em">The values are
different than on non&minus;zoned devices. Each new super
block is appended to the end of the zone, once it's filled,
the zone is reset and writes continue to the next one.
Looking up the latest super block needs to read offsets of
both zones and determine the last written version.</p>

<p style="margin-left:11%; margin-top: 1em">The amount of
space reserved for super block depends on the zone size. The
secondary and tertiary copies are at distant offsets as the
capacity of the devices is expected to be large, tens of
terabytes. Maximum zone size supported is 8GiB, which would
mean that e.g. offset 0&minus;16GiB would be reserved just
for the super block on a hypothetical device of that zone
size. This is wasteful but required to guarantee crash
safety.</p>

<p style="margin-left:11%; margin-top: 1em"><b>Devices <br>
Real hardware</b> <br>
The WD Ultrastar series 600 advertises HM&minus;SMR, i.e.
the host&minus;managed zoned mode. There are two more: DA
(device managed, no zoned information exported to the
system), HA (host aware, can be used as regular disk but
zoned writes improve performance). There are not many
devices available at the moment, the information about exact
zoned mode is hard to find, check data sheets or community
sources gathering information from real devices.</p>

<p style="margin-left:11%; margin-top: 1em">Note: zoned
mode won't work with DM&minus;SMR disks.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="75%">


<p style="margin-top: 1em">Ultrastar&Acirc;&reg; DC ZN540
NVMe ZNS SSD (<i>product brief</i>)</p></td>
<td width="11%">
</td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Emulated:
null_blk</b> <br>
The driver <i>null_blk</i> provides memory backed device and
is suitable for testing. There are some quirks setting up
the devices. The module must be loaded with
<i>nr_devices=0</i> or the numbering of device nodes will be
offset. The <i>configfs</i> must be mounted at
<i>/sys/kernel/config</i> and the administration of the
null_blk devices is done in <i>/sys/kernel/config/nullb</i>.
The device nodes are named like <i>/dev/nullb0</i> and are
numbered sequentially. NOTE: the device name may be
different than the named directory in sysfs!</p>

<p style="margin-left:11%; margin-top: 1em">Setup:</p>

<pre style="margin-left:15%; margin-top: 1em">modprobe&nbsp;configfs
modprobe&nbsp;null_blk&nbsp;nr_devices=0</pre>


<p style="margin-left:11%; margin-top: 1em">Create a device
<i>mydev</i>, assuming no other previously created devices,
size is 2048MiB, zone size 256MiB. There are more tunable
parameters, this is a minimal example taking defaults:</p>

<pre style="margin-left:15%; margin-top: 1em">cd&nbsp;/sys/kernel/config/nullb/
mkdir&nbsp;mydev
cd&nbsp;mydev
echo&nbsp;2048&nbsp;&gt;&nbsp;size
echo&nbsp;1&nbsp;&gt;&nbsp;zoned
echo&nbsp;1&nbsp;&gt;&nbsp;memory_backed
echo&nbsp;256&nbsp;&gt;&nbsp;zone_size
echo&nbsp;1&nbsp;&gt;&nbsp;power</pre>


<p style="margin-left:11%; margin-top: 1em">This will
create a device <i>/dev/nullb0</i> and the value of file
<i>index</i> will match the ending number of the device
node.</p>

<p style="margin-left:11%; margin-top: 1em">Remove the
device:</p>

<pre style="margin-left:15%; margin-top: 1em">rmdir&nbsp;/sys/kernel/config/nullb/mydev</pre>


<p style="margin-left:11%; margin-top: 1em">Then continue
with <i>mkfs.btrfs /dev/nullb0</i>, the zoned mode is
auto&minus;detected.</p>

<p style="margin-left:11%; margin-top: 1em">For
convenience, there's a script wrapping the basic null_blk
management operations
<i>https://github.com/kdave/nullb.git</i>, the above
commands become:</p>

<pre style="margin-left:15%; margin-top: 1em">nullb setup
nullb create &minus;s 2g &minus;z 256
mkfs.btrfs /dev/nullb0
...
nullb rm nullb0</pre>


<p style="margin-left:11%; margin-top: 1em"><b>Emulated:
TCMU runner</b> <br>
TCMU is a framework to emulate SCSI devices in userspace,
providing various backends for the storage, with zoned
support as well. A file&minus;backed zoned device can
provide more options for larger storage and zone size.
Please follow the instructions at
<i>https://zonedstorage.io/projects/tcmu&minus;runner/</i>
.</p>


<p style="margin-left:11%; margin-top: 1em"><b>Compatibility,
incompatibility</b></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">the feature sets an incompat bit
and requires new kernel to access the filesystem (for both
read and write)</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>superblock needs to be handled in a special way, there
are still 3 copies but at different offsets (0, 512GiB,
4TiB) and the 2 consecutive zones are a ring buffer of the
superblocks, finding the latest one needs reading it from
the write pointer or do a full scan of the zones</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>mixing zoned and non zoned devices is possible (zones
are emulated) but is recommended only for testing</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>mixing zoned devices with different zone sizes is not
possible</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>zone sizes must be power of two, zone sizes of real
devices are e.g. 256MiB or 1GiB, larger size is expected,
maximum zone size supported by btrfs is 8GiB</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Status,
stability, reporting bugs</b> <br>
The zoned mode has been released in 5.12 and there are still
some rough edges and corner cases one can hit during
testing. Please report bugs to
<i>https://github.com/naota/linux/issues/</i> .</p>


<p style="margin-left:11%; margin-top: 1em"><b>References</b></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="35%">



<p style="margin-top: 1em"><i>https://zonedstorage.io</i></p> </td>
<td width="51%">
</td></tr>
</table>

<p style="margin-left:14%;">&bull;</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%"></td>
<td width="2%"></td>
<td width="83%">



<p style="margin-top: 1em"><i>https://zonedstorage.io/projects/libzbc/</i>
&minus;&minus; <i>libzbc</i> is library and set of tools to
directly manipulate devices with ZBC/ZAC support</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="83%">


<p><i>https://zonedstorage.io/projects/libzbd/</i>
&minus;&minus; <i>libzbd</i> uses the kernel provided zoned
block device interface based on the ioctl() system calls</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="4%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="83%">
</td></tr>
</table>


<p style="margin-left:14%; margin-top: 1em"><i>https://hddscan.com/blog/2020/hdd&minus;wd&minus;smr.html</i>
&minus;&minus; some details about exact device types</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">



<p style="margin-top: 1em"><i>https://lwn.net/Articles/853308/</i>
&minus;&minus; <i>Btrfs on zoned block devices</i></p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">



<p><i>https://www.usenix.org/conference/vault20/presentation/bjorling</i>
&minus;&minus; Zone Append: A New Way of Writing to Zoned
Storage</p> </td></tr>
</table>

<h2>CONTROL DEVICE
<a name="CONTROL DEVICE"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">There's a
character special device <i>/dev/btrfs&minus;control</i>
with major and minor numbers 10 and 234 (the device can be
found under the 'misc' category).</p>

<pre style="margin-left:15%; margin-top: 1em">$ ls &minus;l /dev/btrfs&minus;control
crw&minus;&minus;&minus;&minus;&minus;&minus;&minus; 1 root root 10, 234 Jan  1 12:00 /dev/btrfs&minus;control</pre>


<p style="margin-left:11%; margin-top: 1em">The device
accepts some ioctl calls that can perform following actions
on the filesystem module:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">scan devices for btrfs
filesystem (i.e. to let multi&minus;device filesystems mount
automatically) and register them with the kernel module</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>similar to scan, but also wait until the device scanning
process is finished for a given filesystem</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>get the supported features (can be also found under
<i>/sys/fs/btrfs/features</i>)</p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">The device is
created when btrfs is initialized, either as a module or a
built&minus;in functionality and makes sense only in
connection with that. Running e.g. mkfs without the module
loaded will not register the device and will probably warn
about that.</p>

<p style="margin-left:11%; margin-top: 1em">In rare cases
when the module is loaded but the device is not present
(most likely accidentally deleted), it's possible to
recreate it by</p>

<pre style="margin-left:15%; margin-top: 1em"># mknod &minus;&minus;mode=600 /dev/btrfs&minus;control c 10 234</pre>


<p style="margin-left:11%; margin-top: 1em">or (since 5.11)
by a convenience command</p>

<pre style="margin-left:15%; margin-top: 1em"># btrfs rescue create&minus;control&minus;device</pre>


<p style="margin-left:11%; margin-top: 1em">The control
device is not strictly required but the device scanning will
not work and a workaround would need to be used to mount a
multi&minus;device filesystem. The mount option
<i>device</i> can trigger the device scanning during mount,
see also <b>btrfs device scan</b>.</p>

<h2>FILESYSTEM WITH MULTIPLE PROFILES
<a name="FILESYSTEM WITH MULTIPLE PROFILES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">It is possible
that a btrfs filesystem contains multiple block group
profiles of the same type. This could happen when a profile
conversion using balance filters is interrupted (see
<i>btrfs&minus;balance(8)</i>). Some <b>btrfs</b> commands
perform a test to detect this kind of condition and print a
warning like this:</p>

<pre style="margin-left:15%; margin-top: 1em">WARNING: Multiple block group profiles detected, see 'man btrfs(5)'.
WARNING:   Data: single, raid1
WARNING:   Metadata: single, raid1</pre>


<p style="margin-left:11%; margin-top: 1em">The
corresponding output of <b>btrfs filesystem df</b> might
look like:</p>

<pre style="margin-left:15%; margin-top: 1em">WARNING: Multiple block group profiles detected, see 'man btrfs(5)'.
WARNING:   Data: single, raid1
WARNING:   Metadata: single, raid1
Data, RAID1: total=832.00MiB, used=0.00B
Data, single: total=1.63GiB, used=0.00B
System, single: total=4.00MiB, used=16.00KiB
Metadata, single: total=8.00MiB, used=112.00KiB
Metadata, RAID1: total=64.00MiB, used=32.00KiB
GlobalReserve, single: total=16.25MiB, used=0.00B</pre>


<p style="margin-left:11%; margin-top: 1em">There's more
than one line for type <i>Data</i> and <i>Metadata</i>,
while the profiles are <i>single</i> and <i>RAID1</i>.</p>

<p style="margin-left:11%; margin-top: 1em">This state of
the filesystem OK but most likely needs the
user/administrator to take an action and finish the
interrupted tasks. This cannot be easily done automatically,
also the user knows the expected final profiles.</p>

<p style="margin-left:11%; margin-top: 1em">In the example
above, the filesystem started as a single device and
<i>single</i> block group profile. Then another device was
added, followed by balance with <i>convert=raid1</i> but for
some reason hasn't finished. Restarting the balance with
<i>convert=raid1</i> will continue and end up with
filesystem with all block group profiles <i>RAID1</i>.</p>


<p style="margin-left:11%; margin-top: 1em"><b>NOTE:</b></p>

<p style="margin-left:15%;">If you're familiar with balance
filters, you can use
<i>convert=raid1,profiles=single,soft</i>, which will take
only the unconverted <i>single</i> profiles and convert them
to <i>raid1</i>. This may speed up the conversion as it
would not try to rewrite the already convert <i>raid1</i>
profiles.</p>

<p style="margin-left:11%; margin-top: 1em">Having just one
profile is desired as this also clearly defines the profile
of newly allocated block groups, otherwise this depends on
internal allocation policy. When there are multiple profiles
present, the order of selection is RAID56, RAID10, RAID1,
RAID0 as long as the device number constraints are
satisfied.</p>

<p style="margin-left:11%; margin-top: 1em">Commands that
print the warning were chosen so they're brought to user
attention when the filesystem state is being changed in that
regard. This is: <b>device add</b>, <b>device delete</b>,
<b>balance cancel</b>, <b>balance pause</b>. Commands that
report space usage: <b>filesystem df</b>, <b>device
usage</b>. The command <b>filesystem usage</b> provides a
line in the overall summary:</p>

<pre style="margin-left:15%; margin-top: 1em">Multiple profiles:                 yes (data, metadata)</pre>


<h2>SEEDING DEVICE
<a name="SEEDING DEVICE"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The COW
mechanism and multiple devices under one hood enable an
interesting concept, called a seeding device: extending a
read&minus;only filesystem on a device with another device
that captures all writes. For example imagine an immutable
golden image of an operating system enhanced with another
device that allows to use the data from the golden image and
normal operation. This idea originated on CD&minus;ROMs with
base OS and allowing to use them for live systems, but this
became obsolete. There are technologies providing similar
functionality, like <i>unionmount</i>, <i>overlayfs</i> or
<i>qcow2</i> image snapshot.</p>

<p style="margin-left:11%; margin-top: 1em">The seeding
device starts as a normal filesystem, once the contents is
ready, <b>btrfstune &minus;S 1</b> is used to flag it as a
seeding device. Mounting such device will not allow any
writes, except adding a new device by <b>btrfs device
add</b>. Then the filesystem can be remounted as
read&minus;write.</p>

<p style="margin-left:11%; margin-top: 1em">Given that the
filesystem on the seeding device is always recognized as
read&minus;only, it can be used to seed multiple filesystems
from one device at the same time. The UUID that is normally
attached to a device is automatically changed to a random
UUID on each mount.</p>

<p style="margin-left:11%; margin-top: 1em">Once the
seeding device is mounted, it needs the writable device.
After adding it, something like <b>remount &minus;o
remount,rw /path</b> makes the filesystem at <i>/path</i>
ready for use. The simplest use case is to throw away all
changes by unmounting the filesystem when convenient.</p>

<p style="margin-left:11%; margin-top: 1em">Alternatively,
deleting the seeding device from the filesystem can turn it
into a normal filesystem, provided that the writable device
can also contain all the data from the seeding device.</p>

<p style="margin-left:11%; margin-top: 1em">The seeding
device flag can be cleared again by <b>btrfstune &minus;f
&minus;S 0</b>, e.g. allowing to update with newer data but
please note that this will invalidate all existing
filesystems that use this particular seeding device. This
works for some use cases, not for others, and the forcing
flag to the command is mandatory to avoid accidental
mistakes.</p>

<p style="margin-left:11%; margin-top: 1em">Example how to
create and use one seeding device:</p>
<pre style="margin-left:15%; margin-top: 1em"># mkfs.btrfs /dev/sda
# mount /dev/sda /mnt/mnt1
... fill mnt1 with data
# umount /mnt/mnt1

# btrfstune &minus;S 1 /dev/sda


# mount /dev/sda /mnt/mnt1
# btrfs device add /dev/sdb /mnt/mnt1
# mount &minus;o remount,rw /mnt/mnt1
... /mnt/mnt1 is now writable</pre>


<p style="margin-left:11%; margin-top: 1em">Now
<i>/mnt/mnt1</i> can be used normally. The device
<i>/dev/sda</i> can be mounted again with a another writable
device:</p>

<pre style="margin-left:15%; margin-top: 1em"># mount /dev/sda /mnt/mnt2
# btrfs device add /dev/sdc /mnt/mnt2
# mount &minus;o remount,rw /mnt/mnt2
... /mnt/mnt2 is now writable</pre>


<p style="margin-left:11%; margin-top: 1em">The writable
device (<i>/dev/sdb</i>) can be decoupled from the seeding
device and used independently:</p>

<pre style="margin-left:15%; margin-top: 1em"># btrfs device delete /dev/sda /mnt/mnt1</pre>


<p style="margin-left:11%; margin-top: 1em">As the contents
originated in the seeding device, it's possible to turn
<i>/dev/sdb</i> to a seeding device again and repeat the
whole process.</p>

<p style="margin-left:11%; margin-top: 1em">A few things to
note:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">it's recommended to use only
single device for the seeding device, it works for multiple
devices but the <i>single</i> profile must be used in order
to make the seeding device deletion work</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>block group profiles <i>single</i> and <i>dup</i>
support the use cases above</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>the label is copied from the seeding device and can be
changed by <b>btrfs filesystem label</b></p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>each new mount of the seeding device gets a new random
UUID</p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Chained
seeding devices</b> <br>
Though it's not recommended and is rather an obscure and
untested use case, chaining seeding devices is possible. In
the first example, the writable device <i>/dev/sdb</i> can
be turned onto another seeding device again, depending on
the unchanged seeding device <i>/dev/sda</i>. Then using
<i>/dev/sdb</i> as the primary seeding device it can be
extended with another writable device, say <i>/dev/sdd</i>,
and it continues as before as a simple tree structure on
devices.</p>
<pre style="margin-left:15%; margin-top: 1em"># mkfs.btrfs /dev/sda
# mount /dev/sda /mnt/mnt1
... fill mnt1 with data
# umount /mnt/mnt1

# btrfstune &minus;S 1 /dev/sda

# mount /dev/sda /mnt/mnt1
# btrfs device add /dev/sdb /mnt/mnt1
# mount &minus;o remount,rw /mnt/mnt1
... /mnt/mnt1 is now writable
# umount /mnt/mnt1

# btrfstune &minus;S 1 /dev/sdb


# mount /dev/sdb /mnt/mnt1
# btrfs device add /dev/sdc /mnt
# mount &minus;o remount,rw /mnt/mnt1
... /mnt/mnt1 is now writable
# umount /mnt/mnt1</pre>


<p style="margin-left:11%; margin-top: 1em">As a result we
have:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em"><i>sda</i> is a single seeding
device, with its initial contents</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>sdb</i> is a seeding device but requires <i>sda</i>,
the contents are from the time when <i>sdb</i> is made
seeding, i.e. contents of <i>sda</i> with any later
changes</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>sdc</i> last writable, can be made a seeding one the
same way as was <i>sdb</i>, preserving its contents and
depending on <i>sda</i> and <i>sdb</i></p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">As long as the
seeding devices are unmodified and available, they can be
used to start another branch.</p>

<h2>RAID56 STATUS AND RECOMMENDED PRACTICES
<a name="RAID56 STATUS AND RECOMMENDED PRACTICES"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em">The RAID56
feature provides striping and parity over several devices,
same as the traditional RAID5/6. There are some
implementation and design deficiencies that make it
unreliable for some corner cases and the feature <b>should
not be used in production, only for evaluation or
testing</b>. The power failure safety for metadata with
RAID56 is not 100%.</p>


<p style="margin-left:11%; margin-top: 1em"><b>Metadata</b>
<br>
Do not use <i>raid5</i> nor <i>raid6</i> for metadata. Use
<i>raid1</i> or <i>raid1c3</i> respectively.</p>

<p style="margin-left:11%; margin-top: 1em">The substitute
profiles provide the same guarantees against loss of 1 or 2
devices, and in some respect can be an improvement.
Recovering from one missing device will only need to access
the remaining 1st or 2nd copy, that in general may be stored
on some other devices due to the way RAID1 works on btrfs,
unlike on a striped profile (similar to <i>raid0</i>) that
would need all devices all the time.</p>

<p style="margin-left:11%; margin-top: 1em">The space
allocation pattern and consumption is different (e.g. on N
devices): for <i>raid5</i> as an example, a 1GiB chunk is
reserved on each device, while with <i>raid1</i> there's
each 1GiB chunk stored on 2 devices. The consumption of each
1GiB of used metadata is then <i>N * 1GiB</i> for vs <i>2 *
1GiB</i>. Using <i>raid1</i> is also more convenient for
balancing/converting to other profile due to lower
requirement on the available chunk space.</p>


<p style="margin-left:11%; margin-top: 1em"><b>Missing/incomplete
support</b> <br>
When RAID56 is on the same filesystem with different raid
profiles, the space reporting is inaccurate, e.g. <b>df</b>,
<b>btrfs filesystem df</b> or <b>btrfs filesystem usage</b>.
When there's only a one profile per block group type (e.g.
RAID5 for data) the reporting is accurate.</p>

<p style="margin-left:11%; margin-top: 1em">When scrub is
started on a RAID56 filesystem, it's started on all devices
that degrade the performance. The workaround is to start it
on each device separately. Due to that the device stats may
not match the actual state and some errors might get
reported multiple times.</p>

<p style="margin-left:11%; margin-top: 1em">The <i>write
hole</i> problem. An unclean shutdown could leave a
partially written stripe in a state where the some stripe
ranges and the parity are from the old writes and some are
new. The information which is which is not tracked. Write
journal is not implemented. Alternatively a full
read&minus;modify&minus;write would make sure that a full
stripe is always written, avoiding the write hole
completely, but performance in that case turned out to be
too bad for use.</p>

<p style="margin-left:11%; margin-top: 1em">The striping
happens on all available devices (at the time the chunks
were allocated), so in case a new device is added it may not
be utilized immediately and would require a rebalance. A
fixed configured stripe width is not implemented.</p>

<h2>STORAGE MODEL, HARDWARE CONSIDERATIONS
<a name="STORAGE MODEL, HARDWARE CONSIDERATIONS"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>Storage
model</b> <i><br>
A storage model is a model that captures key physical
aspects of data structure in a data store. A filesystem is
the logical structure organizing data on top of the storage
device.</i></p>

<p style="margin-left:11%; margin-top: 1em">The filesystem
assumes several features or limitations of the storage
device and utilizes them or applies measures to guarantee
reliability. BTRFS in particular is based on a COW (copy on
write) mode of writing, i.e. not updating data in place but
rather writing a new copy to a different location and then
atomically switching the pointers.</p>

<p style="margin-left:11%; margin-top: 1em">In an ideal
world, the device does what it promises. The filesystem
assumes that this may not be true so additional mechanisms
are applied to either detect misbehaving hardware or get
valid data by other means. The devices may (and do) apply
their own detection and repair mechanisms but we won't
assume any.</p>

<p style="margin-left:11%; margin-top: 1em">The following
assumptions about storage devices are considered (sorted by
importance, numbers are for further reference):</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="3%">


<p style="margin-top: 1em">1.</p></td>
<td width="1%"></td>
<td width="85%">


<p style="margin-top: 1em">atomicity of reads and writes of
blocks/sectors (the smallest unit of data the device
presents to the upper layers)</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="3%">


<p>2.</p></td>
<td width="1%"></td>
<td width="85%">


<p>there's a flush command that instructs the device to
forcibly order writes before and after the command;
alternatively there's a barrier command that facilitates the
ordering but may not flush the data</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="3%">


<p>3.</p></td>
<td width="1%"></td>
<td width="85%">


<p>data sent to write to a given device offset will be
written without further changes to the data and to the
offset</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="3%">


<p>4.</p></td>
<td width="1%"></td>
<td width="85%">


<p>writes can be reordered by the device, unless explicitly
serialized by the flush command</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="3%">


<p>5.</p></td>
<td width="1%"></td>
<td width="85%">


<p>reads and writes can be freely reordered and
interleaved</p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">The consistency
model of BTRFS builds on these assumptions. The logical data
updates are grouped, into a generation, written on the
device, serialized by the flush command and then the super
block is written ending the generation. All logical links
among metadata comprising a consistent view of the data may
not cross the generation boundary.</p>

<p style="margin-left:11%; margin-top: 1em"><b>When things
go wrong <br>
No or partial atomicity of block reads/writes (1)</b></p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em"><i>Problem</i>: a partial block
contents is written (<i>torn write</i>), e.g. due to a power
glitch or other electronics failure during the
read/write</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>Detection</i>: checksum mismatch on read</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>Repair</i>: use another copy or rebuild from multiple
blocks using some encoding scheme</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>The flush
command does not flush (2)</b></p>

<p style="margin-left:11%; margin-top: 1em">This is perhaps
the most serious problem and impossible to mitigate by
filesystem without limitations and design restrictions. What
could happen in the worst case is that writes from one
generation bleed to another one, while still letting the
filesystem consider the generations isolated. Crash at any
point would leave data on the device in an inconsistent
state without any hint what exactly got written, what is
missing and leading to stale metadata link information.</p>

<p style="margin-left:11%; margin-top: 1em">Devices usually
honor the flush command, but for performance reasons may do
internal caching, where the flushed data are not yet
persistently stored. A power failure could lead to a similar
scenario as above, although it's less likely that later
writes would be written before the cached ones. This is
beyond what a filesystem can take into account. Devices or
controllers are usually equipped with batteries or
capacitors to write the cache contents even after power is
cut. (<i>Battery backed write cache</i>)</p>

<p style="margin-left:11%; margin-top: 1em"><b>Data get
silently changed on write (3)</b></p>

<p style="margin-left:11%; margin-top: 1em">Such thing
should not happen frequently, but still can happen
spuriously due the complex internal workings of devices or
physical effects of the storage media itself.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em"><i>Problem</i>: while the data
are written atomically, the contents get changed</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>Detection</i>: checksum mismatch on read</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>Repair</i>: use another copy or rebuild from multiple
blocks using some encoding scheme</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Data get
silently written to another offset (3)</b></p>

<p style="margin-left:11%; margin-top: 1em">This would be
another serious problem as the filesystem has no information
when it happens. For that reason the measures have to be
done ahead of time. This problem is also commonly called
<i>ghost write</i>.</p>

<p style="margin-left:11%; margin-top: 1em">The metadata
blocks have the checksum embedded in the blocks, so a
correct atomic write would not corrupt the checksum. It's
likely that after reading such block the data inside would
not be consistent with the rest. To rule that out there's
embedded block number in the metadata block. It's the
logical block number because this is what the logical
structure expects and verifies.</p>

<p style="margin-left:11%; margin-top: 1em">The following
is based on information publicly available, user feedback,
community discussions or bug report analyses. It's not
complete and further research is encouraged when in
doubt.</p>

<p style="margin-left:11%; margin-top: 1em"><b>Main
memory</b> <br>
The data structures and raw data blocks are temporarily
stored in computer memory before they get written to the
device. It is critical that memory is reliable because even
simple bit flips can have vast consequences and lead to
damaged structures, not only in the filesystem but in the
whole operating system.</p>

<p style="margin-left:11%; margin-top: 1em">Based on
experience in the community, memory bit flips are more
common than one would think. When it happens, it's reported
by the tree&minus;checker or by a checksum mismatch after
reading blocks. There are some very obvious instances of bit
flips that happen, e.g. in an ordered sequence of keys in
metadata blocks. We can easily infer from the other data
what values get damaged and how. However, fixing that is not
straightforward and would require cross&minus;referencing
data from the entire filesystem to see the scope.</p>

<p style="margin-left:11%; margin-top: 1em">If available,
ECC memory should lower the chances of bit flips, but this
type of memory is not available in all cases. A memory test
should be performed in case there's a visible bit flip
pattern, though this may not detect a faulty memory module
because the actual load of the system could be the factor
making the problems appear. In recent years attacks on how
the memory modules operate have been demonstrated
(<i>rowhammer</i>) achieving specific bits to be flipped.
While these were targeted, this shows that a series of reads
or writes can affect unrelated parts of memory.</p>

<p style="margin-left:11%; margin-top: 1em">Further
reading:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="61%">



<p style="margin-top: 1em"><i>https://en.wikipedia.org/wiki/Row_hammer</i></p> </td>
<td width="25%">
</td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">What to do:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">run <i>memtest</i>, note that
sometimes memory errors happen only when the system is under
heavy load that the default memtest cannot trigger</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>memory errors may appear as filesystem going
read&minus;only due to &quot;pre write&quot; check, that
verify meta data before they get written but fail some basic
consistency checks</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Direct
memory access (DMA)</b> <br>
Another class of errors is related to DMA (direct memory
access) performed by device drivers. While this could be
considered a software error, the data transfers that happen
without CPU assistance may accidentally corrupt other pages.
Storage devices utilize DMA for performance reasons, the
filesystem structures and data pages are passed back and
forth, making errors possible in case page life time is not
properly tracked.</p>

<p style="margin-left:11%; margin-top: 1em">There are lots
of quirks (device&minus;specific workarounds) in Linux
kernel drivers (regarding not only DMA) that are added when
found. The quirks may avoid specific errors or disable some
features to avoid worse problems.</p>

<p style="margin-left:11%; margin-top: 1em">What to do:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">use up&minus;to&minus;date
kernel (recent releases or maintained long term support
versions)</p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>as this may be caused by faulty drivers, keep the
systems up&minus;to&minus;date</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Rotational
disks (HDD)</b> <br>
Rotational HDDs typically fail at the level of individual
sectors or small clusters. Read failures are caught on the
levels below the filesystem and are returned to the user as
<i>EIO &minus; Input/output error</i>. Reading the blocks
repeatedly may return the data eventually, but this is
better done by specialized tools and filesystem takes the
result of the lower layers. Rewriting the sectors may
trigger internal remapping but this inevitably leads to data
loss.</p>

<p style="margin-left:11%; margin-top: 1em">Disk firmware
is technically software but from the filesystem perspective
is part of the hardware. IO requests are processed, and
caching or various other optimizations are performed, which
may lead to bugs under high load or unexpected physical
conditions or unsupported use cases.</p>

<p style="margin-left:11%; margin-top: 1em">Disks are
connected by cables with two ends, both of which can cause
problems when not attached properly. Data transfers are
protected by checksums and the lower layers try hard to
transfer the data correctly or not at all. The errors from
badly&minus;connecting cables may manifest as large amount
of failed read or write requests, or as short error bursts
depending on physical conditions.</p>

<p style="margin-left:11%; margin-top: 1em">What to do:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="54%">


<p style="margin-top: 1em">check <b>smartctl</b> for
potential issues</p></td>
<td width="32%">
</td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Solid state
drives (SSD)</b> <br>
The mechanism of information storage is different from HDDs
and this affects the failure mode as well. The data are
stored in cells grouped in large blocks with limited number
of resets and other write constraints. The firmware tries to
avoid unnecessary resets and performs optimizations to
maximize the storage media lifetime. The known techniques
are deduplication (blocks with same fingerprint/hash are
mapped to same physical block), compression or internal
remapping and garbage collection of used memory cells. Due
to the additional processing there are measures to verity
the data e.g. by ECC codes.</p>

<p style="margin-left:11%; margin-top: 1em">The
observations of failing SSDs show that the whole electronic
fails at once or affects a lot of data (e.g. stored on one
chip). Recovering such data may need specialized equipment
and reading data repeatedly does not help as it's possible
with HDDs.</p>

<p style="margin-left:11%; margin-top: 1em">There are
several technologies of the memory cells with different
characteristics and price. The lifetime is directly affected
by the type and frequency of data written. Writing &quot;too
much&quot; distinct data (e.g. encrypted) may render the
internal deduplication ineffective and lead to a lot of
rewrites and increased wear of the memory cells.</p>

<p style="margin-left:11%; margin-top: 1em">There are
several technologies and manufacturers so it's hard to
describe them but there are some that exhibit similar
behaviour:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">expensive SSD will use more
durable memory cells and is optimized for reliability and
high load</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>cheap SSD is projected for a lower load (&quot;desktop
user&quot;) and is optimized for cost, it may employ the
optimizations and/or extended error reporting partially or
not at all</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">It's not
possible to reliably determine the expected lifetime of an
SSD due to lack of information about how it works or due to
lack of reliable stats provided by the device.</p>

<p style="margin-left:11%; margin-top: 1em">Metadata writes
tend to be the biggest component of lifetime writes to a
SSD, so there is some value in reducing them. Depending on
the device class (high end/low end) the features like DUP
block group profiles may affect the reliability in both
ways:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em"><i>high end</i> are typically
more reliable and using <i>single</i> for data and metadata
could be suitable to reduce device wear</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p><i>low end</i> could lack ability to identify errors so
an additional redundancy at the filesystem level (checksums,
<i>DUP</i>) could help</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">Only users who
consume 50 to 100% of the SSD's actual lifetime writes need
to be concerned by the write amplification of btrfs DUP
metadata. Most users will be far below 50% of the actual
lifetime, or will write the drive to death and discover how
many writes 100% of the actual lifetime was. SSD firmware
often adds its own write multipliers that can be arbitrary
and unpredictable and dependent on application behavior, and
these will typically have far greater effect on SSD lifespan
than DUP metadata. It's more or less impossible to predict
when a SSD will run out of lifetime writes to within a
factor of two, so it's hard to justify wear reduction as a
benefit.</p>

<p style="margin-left:11%; margin-top: 1em">Further
reading:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">



<p style="margin-top: 1em"><i>https://www.snia.org/educational&minus;library/ssd&minus;and&minus;deduplication&minus;end&minus;spinning&minus;disk&minus;2012</i></p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">



<p><i>https://www.snia.org/educational&minus;library/realities&minus;solid&minus;state&minus;storage&minus;2013&minus;2013</i></p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">



<p><i>https://www.snia.org/educational&minus;library/ssd&minus;performance&minus;primer&minus;2013</i></p> </td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">



<p><i>https://www.snia.org/educational&minus;library/how&minus;controllers&minus;maximize&minus;ssd&minus;life&minus;2013</i></p> </td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em">What to do:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="84%">


<p style="margin-top: 1em">run <b>smartctl</b> or
self&minus;tests to look for potential issues</p></td>
<td width="2%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="84%">


<p>keep the firmware up&minus;to&minus;date</p></td>
<td width="2%">
</td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>NVM express,
non&minus;volatile memory (NVMe)</b> <br>
NVMe is a type of persistent memory usually connected over a
system bus (PCIe) or similar interface and the speeds are an
order of magnitude faster than SSD. It is also a
non&minus;rotating type of storage, and is not typically
connected by a cable. It's not a SCSI type device either but
rather a complete specification for logical device
interface.</p>

<p style="margin-left:11%; margin-top: 1em">In a way the
errors could be compared to a combination of SSD class and
regular memory. Errors may exhibit as random bit flips or IO
failures. There are tools to access the internal log
(<b>nvme log</b> and <b>nvme&minus;cli</b>) for a more
detailed analysis.</p>

<p style="margin-left:11%; margin-top: 1em">There are
separate error detection and correction steps performed e.g.
on the bus level and in most cases never making in to the
filesystem level. Once this happens it could mean there's
some systematic error like overheating or bad physical
connection of the device. You may want to run
self&minus;tests (using <b>smartctl</b>).</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="72%">



<p style="margin-top: 1em"><i>https://en.wikipedia.org/wiki/NVM_Express</i></p> </td>
<td width="14%">
</td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="72%">



<p><i>https://www.smartmontools.org/wiki/NVMe_Support</i></p> </td>
<td width="14%">
</td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>Drive
firmware</b> <br>
Firmware is technically still software but embedded into the
hardware. As all software has bugs, so does firmware.
Storage devices can update the firmware and fix known bugs.
In some cases the it's possible to avoid certain bugs by
quirks (device&minus;specific workarounds) in Linux
kernel.</p>

<p style="margin-left:11%; margin-top: 1em">A faulty
firmware can cause wide range of corruptions from small and
localized to large affecting lots of data. Self&minus;repair
capabilities may not be sufficient.</p>

<p style="margin-left:11%; margin-top: 1em">What to do:</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p style="margin-top: 1em">&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p style="margin-top: 1em">check for firmware updates in
case there are known problems, note that updating firmware
can be risky on itself</p></td></tr>
<tr valign="top" align="left">
<td width="11%"></td>
<td width="1%">


<p>&bull;</p></td>
<td width="2%"></td>
<td width="86%">


<p>use up&minus;to&minus;date kernel (recent releases or
maintained long term support versions)</p></td></tr>
</table>

<p style="margin-left:11%; margin-top: 1em"><b>SD flash
cards</b> <br>
There are a lot of devices with low power consumption and
thus using storage media based on low power consumption too,
typically flash memory stored on a chip enclosed in a
detachable card package. An improperly inserted card may be
damaged by electrical spikes when the device is turned on or
off. The chips storing data in turn may be damaged
permanently. All types of flash memory have a limited number
of rewrites, so the data are internally translated by FTL
(flash translation layer). This is implemented in firmware
(technically a software) and prone to bugs that manifest as
hardware errors.</p>

<p style="margin-left:11%; margin-top: 1em">Adding
redundancy like using DUP profiles for both data and
metadata can help in some cases but a full backup might be
the best option once problems appear and replacing the card
could be required as well.</p>

<p style="margin-left:11%; margin-top: 1em"><b>Hardware as
the main source of filesystem corruptions <br>
If you use unreliable hardware and don't know about that,
don't blame the filesystem when it tells you.</b></p>

<h2>SEE ALSO
<a name="SEE ALSO"></a>
</h2>


<p style="margin-left:11%; margin-top: 1em"><b>acl(5)</b>,
<i>btrfs(8)</i>, <b>chattr(1)</b>, <b>fstrim(8)</b>,
<b>ioctl(2)</b>, <i>mkfs.btrfs(8)</i>, <b>mount(8)</b>,
<b>swapon(8)</b></p>
<hr>
</body>
</html>
